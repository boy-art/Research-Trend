<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>Neural Systems for Face Evaluation</AwardTitle>
    <AwardEffectiveDate>09/01/2008</AwardEffectiveDate>
    <AwardExpirationDate>08/31/2012</AwardExpirationDate>
    <AwardAmount>549992</AwardAmount>
    <AwardInstrument>
      <Value>Continuing grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>04040000</Code>
      <Directorate>
        <LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
      </Directorate>
      <Division>
        <LongName>Division Of Behavioral and Cognitive Sci</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Akaysha Tang</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>People form impressions about other people from surprisingly minimal information, particularly from faces, which are a particularly rich source of social information. Despite the saying "don't judge a book by its cover," people automatically evaluate faces on multiple social dimensions such as competence and trustworthiness, and these evaluations predict important social outcomes ranging from electoral success to judicial sentencing decisions. In order to understand the functional and neural basis of face evaluation, it is necessary to identify the basic dimensions of face evaluation, introduce tools for formally modeling how faces vary on these dimensions, and probe the neural responses to faces that vary on these dimensions. With support from the National Science Foundation, Dr. Alexander Todorov and colleagues at Princeton University will address these questions by combining computer modeling of how faces vary on social dimensions with behavioral studies, Virtual Reality (VR) studies, and brain imaging (functional Magnetic Resonance Imaging) studies. The studies involve not only participants who have typical face perception abilities but also prosopagnosics, those who are unable to recognize individuals by face alone. One current hypothesis is that faces are evaluated on two fundamental dimensions--valence and dominance--that are sensitive to different types of facial information. Valence evaluation of faces tracks expressions signaling whether the person should be avoided (angry expression) or approached (happy expression) and dominance evaluation is sensitive to features signaling physical strength (masculinity and facial maturity). The current studies will investigate how behavioral and brain responses to faces change as a function of their perceived valence and dominance. &lt;br/&gt;&lt;br/&gt;The findings will be central for understanding the neural mechanisms underlying face perception and social cognition. Characterizing the processes of face evaluation is essential for building comprehensive models of person perception and social cognition and, ultimately, understanding the social brain. The findings of this research will be important for social psychologists, cognitive neuroscientists, political scientists, and behavioral economists, and will be of interest to vision and computer scientists. This project also includes opportunities for research experience by undergraduate and graduate students in Social Neuroscience.</AbstractNarration>
    <MinAmdLetterDate>07/29/2008</MinAmdLetterDate>
    <MaxAmdLetterDate>07/07/2010</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>0823749</AwardID>
    <Investigator>
      <FirstName>Alexander</FirstName>
      <LastName>Todorov</LastName>
      <EmailAddress>atodorov@princeton.edu</EmailAddress>
      <StartDate>07/29/2008</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Princeton University</Name>
      <CityName>Princeton</CityName>
      <ZipCode>085442020</ZipCode>
      <PhoneNumber>6092583090</PhoneNumber>
      <StreetAddress>Off. of Research &amp; Proj. Admin.</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>New Jersey</StateName>
      <StateCode>NJ</StateCode>
    </Institution>
    <FoaInformation>
      <Code>0116000</Code>
      <Name>Human Subjects</Name>
    </FoaInformation>
  </Award>
</rootTag>
