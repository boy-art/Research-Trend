<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>RI: Collaborative Research: Feature Discovery and Benchmarks for Exportable Reinforcement Learning</AwardTitle>
    <AwardEffectiveDate>10/01/2007</AwardEffectiveDate>
    <AwardExpirationDate>05/31/2012</AwardExpirationDate>
    <AwardAmount>241000</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05020000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Information &amp; Intelligent Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>James Donlon</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Collaborative Proposal pair: 0713435 (Lead) &amp; 0713148&lt;br/&gt;"Collaborative: RI: Feature Discovery and Benchmarks for exportable Reinforcement Learning"&lt;br/&gt;PI: Ronald Parr, Duke University&lt;br/&gt;PI: Michael L. Littman, Rutgers University&lt;br/&gt;&lt;br/&gt;ABSTRACT&lt;br/&gt;&lt;br/&gt;This project focuses on several aspects of automated feature discovery in the context of reinforcement learning. Badly chosen features cause reinforcement-learning algorithms to fail and, as such, only individuals skilled in feature construction can create successful reinforcement-learning systems for novel tasks. This issue underscores two shortcomings in existing research. First, most existing reinforcement-learning methods cannot generate or discover features automatically and robustly. Second, existing benchmark problems and paradigms for benchmarking do not distinguish adequately between clever algorithm design and clever feature engineering.&lt;br/&gt;&lt;br/&gt;This project addresses these challenges in two-pronged approach. The first prong aims to advance a technical agenda leading to a new approach to feature discovery and model representation. The second prong is the development of a benchmark methodology and repository with a different focus and structure from existing endeavors. The goal for the benchmarking effort will be to produce a set of fair and reproducible experiments that will help elucidate the strengths and weaknesses of existing approaches, while simultaneously introducing challenges to motivate the development of new approaches.</AbstractNarration>
    <MinAmdLetterDate>09/20/2007</MinAmdLetterDate>
    <MaxAmdLetterDate>05/18/2010</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>0713148</AwardID>
    <Investigator>
      <FirstName>Michael</FirstName>
      <LastName>Littman</LastName>
      <EmailAddress>mlittman@cs.brown.edu</EmailAddress>
      <StartDate>09/20/2007</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Rutgers University New Brunswick</Name>
      <CityName>Piscataway</CityName>
      <ZipCode>088543925</ZipCode>
      <PhoneNumber>8489320150</PhoneNumber>
      <StreetAddress>33 Knightsbridge Road</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>New Jersey</StateName>
      <StateCode>NJ</StateCode>
    </Institution>
    <ProgramElement>
      <Code>7495</Code>
      <Text>ROBUST INTELLIGENCE</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>7495</Code>
      <Text>ROBUST INTELLIGENCE</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>9218</Code>
      <Text>BASIC RESEARCH &amp; HUMAN RESORCS</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>9251</Code>
      <Text>RES EXPER FOR UNDERGRAD-SUPPLT</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>HPCC</Code>
      <Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
    </ProgramReference>
  </Award>
</rootTag>
