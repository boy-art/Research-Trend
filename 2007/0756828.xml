<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>Lifelike visual feedback for brain-computer interface</AwardTitle>
    <AwardEffectiveDate>07/01/2008</AwardEffectiveDate>
    <AwardExpirationDate>06/30/2011</AwardExpirationDate>
    <AwardAmount>275437</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>07020000</Code>
      <Directorate>
        <LongName>Directorate For Engineering</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Chem, Bioeng, Env, &amp; Transp Sys</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Ted A. Conway</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>de Sa&lt;br/&gt;0756828&lt;br/&gt;&lt;br/&gt;Brain computer interfaces (BCIs) translate basic mental commands into computer-mediated actions. BCIs allow the user to bypass the peripheral motor system and interact with the world directly through brain activity. These systems are being developed to aid users with motor deficits which can stem from: neurodegenerative disease (such as Lou Gehrig's disease, or ALS), injury (such as spinal cord injury), or even environmental restrictions which make movement difficult or impossible (such as astronauts in space suits). BCI systems typically require extensive user training to generate reproducible and distinct brain waves. Furthermore, until very recently, most BCI systems have interacted with the user in unintuitive or unnatural ways, such as moving a cursor or bar left and right by engaging in two unrelated forms of mental imagery, such as moving the right hand vs. the left foot. Realistic visual feedback of interpreted motor action should substantially improve usability and performance of BCI systems. This hypothesis is based on four observations: 1) humans have evolved to adapt their motor control in response to visual and proprioceptive feedback; 2) rapid motor adaptation is demonstrated in virtual reality experiments; 3) animals improve their neural signal when given visual feedback of their decoded neural activity; and 4) visual feedback of interpreted movement should activate the mirror neuron system, producing a stronger movement signal. The proposed work aims to improve upon current BCI systems based on motor imagery by providing more natural and lifelike feedback. This task can be broken down into 3 main objectives: 1) analyze motor imagery with visual feedback in an offline setting; 2) develop algorithms for real-time EEG analysis; and 3) construct a real-time BCI system utilizing lifelike motion animations as visual feedback. While results of objectives 1 and 2 should each in their own right contribute to the current state of the art in BCI systems, the largest BCI performance and usability gains should be made by introducing lifelike feedback into an online paradigm in the third objective. The proposed system can also be used to study learning and sensory-motor processing in normal subjects by studying their adaptation to the system. It may also inform more costly invasive recording experiments by helping to determine optimal placements of implants. All software written for EEG signal processing and analysis will be made available as add-ons to EEGLAB which is distributed in accordance with University of California policy for research, education, and non-profit purposes. The EEGLAB project is also developing an EEG database in conjunction with the San Diego Supercomputer Center. Representative data sets will be released via this database in accordance with University of California policy.</AbstractNarration>
    <MinAmdLetterDate>03/21/2008</MinAmdLetterDate>
    <MaxAmdLetterDate>03/21/2008</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>0756828</AwardID>
    <Investigator>
      <FirstName>Virginia</FirstName>
      <LastName>de Sa</LastName>
      <EmailAddress>vdesa@cogsci.ucsd.edu</EmailAddress>
      <StartDate>03/21/2008</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>Scott</FirstName>
      <LastName>Makeig</LastName>
      <EmailAddress>smakeig@ucsd.edu</EmailAddress>
      <StartDate>03/21/2008</StartDate>
      <EndDate/>
      <RoleCode>Co-Principal Investigator</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>Howard</FirstName>
      <LastName>Poizner</LastName>
      <EmailAddress>hpoizner@ucsd.edu</EmailAddress>
      <StartDate>03/21/2008</StartDate>
      <EndDate/>
      <RoleCode>Co-Principal Investigator</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>Emanuel</FirstName>
      <LastName>Todorov</LastName>
      <EmailAddress>todorov@cs.washington.edu</EmailAddress>
      <StartDate>03/21/2008</StartDate>
      <EndDate/>
      <RoleCode>Co-Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of California-San Diego</Name>
      <CityName>La Jolla</CityName>
      <ZipCode>920930621</ZipCode>
      <PhoneNumber>8585344896</PhoneNumber>
      <StreetAddress>Office of Contract &amp; Grant Admin</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>California</StateName>
      <StateCode>CA</StateCode>
    </Institution>
    <FoaInformation>
      <Code>0000099</Code>
      <Name>Other Applications NEC</Name>
    </FoaInformation>
    <FoaInformation>
      <Code>0116000</Code>
      <Name>Human Subjects</Name>
    </FoaInformation>
    <ProgramElement>
      <Code>5342</Code>
      <Text>Gen &amp; Age Rel Disabilities Eng</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>0000</Code>
      <Text>UNASSIGNED</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>010E</Code>
      <Text>DISABILITY RES &amp; HOMECARE TECH</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>OTHR</Code>
      <Text>OTHER RESEARCH OR EDUCATION</Text>
    </ProgramReference>
  </Award>
</rootTag>
