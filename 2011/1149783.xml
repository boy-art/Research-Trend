<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>CAREER: Visual Tracking with Online and Prior Learning</AwardTitle>
    <AwardEffectiveDate>01/01/2012</AwardEffectiveDate>
    <AwardExpirationDate>12/31/2017</AwardExpirationDate>
    <AwardAmount>492698</AwardAmount>
    <AwardInstrument>
      <Value>Continuing grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05020000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Information &amp; Intelligent Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Jie Yang</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>This project develops efficient and effective algorithms to handle challenging problems in visual tracking such as drift, heavy occlusion, and failure recovery. The research team is developing an integrated framework in which object detection, tracking and recognition are addressed simultaneously. Within this framework, the prior knowledge is learned from a large set of images pertaining to object classes of interest. Such knowledge serves as long-term memory for the proposed appearance models which are then adapted to unseen new object instances. In addition, a top-down saliency model for each object class of interest is developed in order to handle heavy occlusion and failure recovery. The project has four major components: developing algorithms for learning visual prior and transferring knowledge for online appearance model, designing tracking algorithms that handle draft with the proposed appearance model, modeling top-down saliency maps to handle full occlusion and tracking failure, evaluating state-of-the-art algorithms with a large benchmark dataset. &lt;br/&gt;&lt;br/&gt;This project provides a building block for robust object tracking, which can be applied to motion analysis, surveillance, and multi-object tracking. The developed top-down saliency map provides a flexible way to represent objects, which can be extended to object detection and segmentation. The proposed tracking library and benchmark data set provide a platform for evaluation of advances in object tracking. This research is integrated with education and outreach by courses and activities aimed at attracting students to this field and encouraging interdisciplinary collaborations.</AbstractNarration>
    <MinAmdLetterDate>12/27/2011</MinAmdLetterDate>
    <MaxAmdLetterDate>05/03/2016</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1149783</AwardID>
    <Investigator>
      <FirstName>Ming-Hsuan</FirstName>
      <LastName>Yang</LastName>
      <EmailAddress>mhyang@ucmerced.edu</EmailAddress>
      <StartDate>12/27/2011</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of California - Merced</Name>
      <CityName>Merced</CityName>
      <ZipCode>953435001</ZipCode>
      <PhoneNumber>2097566405</PhoneNumber>
      <StreetAddress>5200 North Lake Road</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>California</StateName>
      <StateCode>CA</StateCode>
    </Institution>
    <ProgramElement>
      <Code>7495</Code>
      <Text>ROBUST INTELLIGENCE</Text>
    </ProgramElement>
    <ProgramElement>
      <Code>7731</Code>
      <Text>OTHER GLOBAL LEARNING &amp; TRNING</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>1045</Code>
      <Text>CAREER: FACULTY EARLY CAR DEV</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>5950</Code>
      <Text>SWITZERLAND</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>5979</Code>
      <Text>Europe and Eurasia</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>7495</Code>
      <Text>ROBUST INTELLIGENCE</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>9251</Code>
      <Text>RES EXPER FOR UNDERGRAD-SUPPLT</Text>
    </ProgramReference>
  </Award>
</rootTag>
