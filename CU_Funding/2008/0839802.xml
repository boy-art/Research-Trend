<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>SBIR Phase I: iGlasses: An Appliance for Improving Speech Understanding in Face-to-Face Communication and Classroom Situations</AwardTitle>
    <AwardEffectiveDate>01/01/2009</AwardEffectiveDate>
    <AwardExpirationDate>06/30/2009</AwardExpirationDate>
    <AwardAmount>99944</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>07070000</Code>
      <Directorate>
        <LongName>Directorate For Engineering</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Industrial Innovation &amp; Partnersh</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Ian M. Bennett</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>This Small Business Innovation Research (SBIR) project will advance the state of the art in human machine interaction, speech, machine learning and assistive technologies. The innovation in the proposed research is to develop and test the technology required to design an embellished eyeglass, which will perform continuous real-time acoustic analysis of the interlocutor's speech and transform several continuous acoustic features of the user's speech into continuous visual features displayed on the eyeglasses. Pilot research has demonstrated that it is possible to recognize robust characteristics of isolated auditory words and to transform them into visible features in real time. The proposed research extends this research to sentences along with tests of different feature detectors and automatic recognition models. &lt;br/&gt;&lt;br/&gt;The proposed activity will impact society by providing a research and theoretical foundation for a system that would be available to all individuals at a very low cost. It does not require literate users because no written information is presented as would be the case in a captioning system; it is age-independent in that it might be used by toddlers, adolescents, and throughout the life span; it is functional for all languages because it is language independent given that all languages share the same phonetic features with highly similar corresponding acoustic characteristics; it would provide significant help for people with hearing aids and cochlear implants; and it would be beneficial for many individuals with language challenges and even for children learning to read.</AbstractNarration>
    <MinAmdLetterDate>11/24/2008</MinAmdLetterDate>
    <MaxAmdLetterDate>11/24/2008</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>0839802</AwardID>
    <Investigator>
      <FirstName>Michael</FirstName>
      <LastName>Cohen</LastName>
      <EmailAddress>michael@animatedspeech.com</EmailAddress>
      <StartDate>11/24/2008</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Animated Speech Corporation</Name>
      <CityName>Burlingame</CityName>
      <ZipCode>940101715</ZipCode>
      <PhoneNumber>8182122913</PhoneNumber>
      <StreetAddress>851 Burlway Road</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>California</StateName>
      <StateCode>CA</StateCode>
    </Institution>
    <FoaInformation>
      <Code>0116000</Code>
      <Name>Human Subjects</Name>
    </FoaInformation>
    <FoaInformation>
      <Code>0308000</Code>
      <Name>Industrial Technology</Name>
    </FoaInformation>
  </Award>
</rootTag>
