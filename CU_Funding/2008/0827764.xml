<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>Neural Basis of Active Perception in Natural Environment</AwardTitle>
    <AwardEffectiveDate>10/01/2008</AwardEffectiveDate>
    <AwardExpirationDate>09/30/2012</AwardExpirationDate>
    <AwardAmount>596821</AwardAmount>
    <AwardInstrument>
      <Value>Continuing grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>04040000</Code>
      <Directorate>
        <LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
      </Directorate>
      <Division>
        <LongName>Division Of Behavioral and Cognitive Sci</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Peter M. Vishton</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Understanding how animals perceive and act upon complex natural environments is one of the most pressing challenges in neuroscience, with applications that have potential to revolutionize not only our understanding of the brain, but also machine vision, artificial intelligence, and robotics. Until now, studying the neural basis of active vision - how visual stimuli give rise to eye movements under diverse task conditions - has largely been restricted to simplified laboratory stimuli, presented to overtrained animals performing stereotypical tasks. With funding from the National Science Foundation, the Canadian Institute of Health Research, and the National Geospatial Intelligence Agency, Dr. Douglas Munoz at Queens University in Canada and Dr. Laurent Itti at the University of Southern California will combine neurophysiology and computational modeling to investigate free viewing in natural environments. Using multi-electrode arrays, this project will record in a deep brain structure, called the superior colliculus (SC). The SC is a layered structure comprising several well-understood neural maps, from purely sensory representations in the superficial layers, to sensorimotor representations linked to the control of eye movements in the deeper layers. The project will start by characterizing responses of neurons in the SC under simple stimulus conditions: When the animal is simply looking at a central fixation cross on a display while small isolated patterns are presented at other visual locations; when the animal searches for an oddball item among an array of distracting items; and when the animal inspects natural images and video clips. The project will extend the investigators' salience map theories and models, and develop a new model of the SC. The complete model will predict, from any image or video clip, which visual locations are more salient, task-relevant, and candidate targets for eye movements.&lt;br/&gt;&lt;br/&gt;The project leverages a cross-disciplinary collaboration between a neurophysiology lab (co-PI Douglas P. Munoz) and a computational modeling lab (PI Laurent Itti). This will allow, through the combination of experiments and modeling, the interpretation of an otherwise undecipherable mass of data collected during natural viewing. Conversely, the theories will guide further experiments. Coupling multi-unit recording with modeling during free-viewing of natural videos has never been attempted before, and it is expected that it will lead to new understanding of how percepts map into actions under natural conditions. The project will support undergraduate and graduate students, and post-doctoral researchers, who will benefit from exposure to combined physiological and computational techniques, as will the investigators' teaching. In addition to publications, all theory and algorithm source code will be freely distributed, and data will be available through the CRCNS data sharing web site. This research is hence expected to lead to new and broadly accessible fundamental advances in the understanding of how animals use visual information to guide behavior, and how one could build machines which act in similar ways when faced with the complex natural world.</AbstractNarration>
    <MinAmdLetterDate>09/19/2008</MinAmdLetterDate>
    <MaxAmdLetterDate>07/28/2010</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>0827764</AwardID>
    <Investigator>
      <FirstName>Doug</FirstName>
      <LastName>Munoz</LastName>
      <EmailAddress>doug@eyeml.queensu.ca</EmailAddress>
      <StartDate>09/19/2008</StartDate>
      <EndDate/>
      <RoleCode>Co-Principal Investigator</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>Laurent</FirstName>
      <LastName>Itti</LastName>
      <EmailAddress>itti@pollux.usc.edu</EmailAddress>
      <StartDate>09/19/2008</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of Southern California</Name>
      <CityName>Los Angeles</CityName>
      <ZipCode>900890001</ZipCode>
      <PhoneNumber>2137407762</PhoneNumber>
      <StreetAddress>University Park</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>California</StateName>
      <StateCode>CA</StateCode>
    </Institution>
    <ProgramElement>
      <Code>7298</Code>
      <Text>COLLABORATIVE RESEARCH</Text>
    </ProgramElement>
    <ProgramElement>
      <Code>7327</Code>
      <Text>CRCNS</Text>
    </ProgramElement>
    <ProgramElement>
      <Code>H448</Code>
      <Text/>
    </ProgramElement>
    <ProgramReference>
      <Code>0000</Code>
      <Text>UNASSIGNED</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>7298</Code>
      <Text>COLLABORATIVE RESEARCH</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>7327</Code>
      <Text>CRCNS</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>OTHR</Code>
      <Text>OTHER RESEARCH OR EDUCATION</Text>
    </ProgramReference>
  </Award>
</rootTag>
