<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>Deterministic Parallel Programming for High Performance Computing</AwardTitle>
    <AwardEffectiveDate>09/01/2008</AwardEffectiveDate>
    <AwardExpirationDate>08/31/2012</AwardExpirationDate>
    <AwardAmount>625000</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05010000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Division of Computing and Communication Foundations</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Almadena Y. Chtchelkanova</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Hardware for High-Performance Computing is advancing at a relentless pace: In the not too distant future we can expect to see systems with over a million of concurrently executing threads, with hardware support for global memory access. On the other hand, we continue to use today the same low-level parallel message passing libraries that we have used in the last 15 years. This causes lower user productivity and does not leverage well modern communication hardware. We propose to explore new language designs that address both problems.&lt;br/&gt;&lt;br/&gt;It is generally accepted that programming in a shared memory model is easier (at least for initial program development): the ability of each thread to access each variable, using a common name space, reduces much of the burden of distributed memory programming. On the other hand, shared memory programming languages generally allow users to write nondeterministic code (where different outcomes are possible) and do not protect the user from memory races (where accesses to shared variables are not synchronized). This results in subtle bugs that are not reproducible and hard to detect. Furthermore, shared memory languages provide limited support for locality control ? resulting in lack of scalability. Nondeterminism is rarely needed in scientific computing, and scalability is essential. &lt;br/&gt;&lt;br/&gt;The PIs believe it is possible to develop languages that will support the large majority of programming patterns used in high-performance-computing; will provide the convenience of a shared-memory model; will prevent, by design, nondeterminism and detect races; and will provide user control of locality. The proposed research will explore the design for such a language and the required support technologies.</AbstractNarration>
    <MinAmdLetterDate>07/31/2008</MinAmdLetterDate>
    <MaxAmdLetterDate>07/31/2008</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>0833128</AwardID>
    <Investigator>
      <FirstName>Marc</FirstName>
      <LastName>Snir</LastName>
      <EmailAddress>snir@illinois.edu</EmailAddress>
      <StartDate>07/31/2008</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of Illinois at Urbana-Champaign</Name>
      <CityName>CHAMPAIGN</CityName>
      <ZipCode>618207473</ZipCode>
      <PhoneNumber>2173332187</PhoneNumber>
      <StreetAddress>SUITE A</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Illinois</StateName>
      <StateCode>IL</StateCode>
    </Institution>
    <FoaInformation>
      <Code>0000912</Code>
      <Name>Computer Science</Name>
    </FoaInformation>
    <ProgramElement>
      <Code>2878</Code>
      <Text>SPECIAL PROJECTS - CCF</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>9218</Code>
      <Text>BASIC RESEARCH &amp; HUMAN RESORCS</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>HPCC</Code>
      <Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
    </ProgramReference>
  </Award>
</rootTag>
