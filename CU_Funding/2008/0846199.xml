<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>Source Coding and Simulation</AwardTitle>
    <AwardEffectiveDate>09/01/2008</AwardEffectiveDate>
    <AwardExpirationDate>02/28/2011</AwardExpirationDate>
    <AwardAmount>244179</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05010000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Division of Computing and Communication Foundations</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>John Cozzens</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>The intimate connection between source coding (data compression,&lt;br/&gt;quantization) and simulation (the generation of a signal with prescribed distributions from a purely random mechanism such as coin flips) has been known for over three decades. Recent results suggest even deeper connections with potentially significant implications for the related problems of compression code design, modeling random processes for the analysis and design of signal processing and coding systems, and understanding the nature and structure of mathematical models of random processes capturing the important properties of signals arising in the real world. This research is concerned with developing precise results characterizing and applying these connections to obtain new insight, theory, and algorithms.&lt;br/&gt;&lt;br/&gt;In 1977 the performance of an optimized source coding system was shown to be bounded by the quality of a constrained simulation of the source, with equality under certain conditions. In 2008 this connection was strengthened by a precise formulation and proof of an information theoretic ``folk theorem'' stating that source coding systems performing near the Shannon optimum yield bit streams that are ``nearly coin flips'' in the rigorous sense of closeness in Ornstein's d-bar process distance. Together these results imply that source coding systems --- including digital speech, audio, image, and video communication and storage systems --- and simulation systems --- comprising stationary codings or filterings of iid bits --- are mathematically approximately equivalent systems, and hence the theory and design algorithms appropriate for one yield corresponding results for the other. This project exploits these connections to develop new theory and design algorithms for codes for compression, simulation, and modeling based on known distributions and on distributions learned from data.</AbstractNarration>
    <MinAmdLetterDate>08/09/2008</MinAmdLetterDate>
    <MaxAmdLetterDate>08/18/2010</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>0846199</AwardID>
    <Investigator>
      <FirstName>Robert</FirstName>
      <LastName>Gray</LastName>
      <EmailAddress>rmgray@stanford.edu</EmailAddress>
      <StartDate>08/09/2008</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Stanford University</Name>
      <CityName>Palo Alto</CityName>
      <ZipCode>943041212</ZipCode>
      <PhoneNumber>6507232300</PhoneNumber>
      <StreetAddress>3160 Porter Drive</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>California</StateName>
      <StateCode>CA</StateCode>
    </Institution>
  </Award>
</rootTag>
