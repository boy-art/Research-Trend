<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>Validating Proof Comprehension Tests in Mathematics</AwardTitle>
    <AwardEffectiveDate>09/15/2013</AwardEffectiveDate>
    <AwardExpirationDate>08/31/2017</AwardExpirationDate>
    <AwardAmount>200000</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>11040200</Code>
      <Directorate>
        <LongName>Direct For Education and Human Resources</LongName>
      </Directorate>
      <Division>
        <LongName>Division Of Undergraduate Education</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Myles G. Boylan</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Intellectual Merit: The primary means for teaching advanced mathematics is through the presentation of mathematical proofs. However, both in the classroom and in mathematics education research, students' understanding of these proofs is rarely assessed. The goal of this project is to develop a student comprehension assessment model of theoretical proofs. Specifically, the project is engaged in generating and validating proof comprehension tests for three proofs in a transition-to-proof course.&lt;br/&gt;&lt;br/&gt;The project has three phases. The first stage is developing open-ended proof comprehension assessment questions for three proofs using the Mejia-Ramos model. A small sample of undergraduate mathematics majors answers these questions in a semi-structured interview and their responses go into the creation a large repository of multiple-choice assessment items. In the second stage a large sample of mathematics majors completes these multiple-choice tests for the three proofs. Using their responses, items that correlate highly with other items in the tests are dropped using a form of factor analysis to produce a reduced version of the multiple-choice tests for these proofs. Finally, a small sample of undergraduate mathematics majors is interviewed as they complete both the open-ended and the short multiple-choice versions of the assessment tests. This stage seeks to verify that the multiple-choice tests are a valid indicator of the test taker's understanding of the three proofs. The result of this process is expected to be three short, multiple-choice proof comprehension tests that are valid indicators of students' understanding of the proofs being studied.&lt;br/&gt;&lt;br/&gt;Broader impact: Better assessments of the extent to which STEM students comprehend the proofs they read are needed to improve the teaching and learning of proof at the university level. The failure of some university students to successfully understand mathematical proofs prevents them from entering STEM disciplines. In the particular case of prospective teachers of mathematics, this failure prevents them from gaining the content knowledge they need to teach mathematics effectively. &lt;br/&gt;&lt;br/&gt;The generation of proof comprehension tests serves urgent needs for mathematicians, mathematics majors, and mathematics education researchers. For mathematics faculty, incomplete assessment of students' comprehension of proofs means they do not receive feedback both on the general quality of their lectures and on specific areas of proofs that students may have found confusing. For mathematics majors, assessment of their comprehension of the proofs they are asked to complete encourages them to invest time in studying these proofs; and meaningful assessment items direct their attention to important aspects of the proof that they may not ordinarily consider. Valid proof comprehension tests are also useful to researchers in undergraduate mathematics education by allowing them to measure the effectiveness of different teaching techniques related to proof presentation and systematically address questions about what aspects of proof students find confusing.</AbstractNarration>
    <MinAmdLetterDate>09/12/2013</MinAmdLetterDate>
    <MaxAmdLetterDate>09/12/2013</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1245625</AwardID>
    <Investigator>
      <FirstName>Keith</FirstName>
      <LastName>Weber</LastName>
      <EmailAddress>keith.weber@gse.rutgers.edu</EmailAddress>
      <StartDate>09/12/2013</StartDate>
      <EndDate/>
      <RoleCode>Co-Principal Investigator</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>Jimmy</FirstName>
      <LastName>de la Torre</LastName>
      <EmailAddress>j.delatorre@rutgers.edu</EmailAddress>
      <StartDate>09/12/2013</StartDate>
      <EndDate/>
      <RoleCode>Co-Principal Investigator</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>Juan Pablo</FirstName>
      <LastName>Mejia-Ramos</LastName>
      <EmailAddress>pablo.mejia@gse.rutgers.edu</EmailAddress>
      <StartDate>09/12/2013</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Rutgers University New Brunswick</Name>
      <CityName>Piscataway</CityName>
      <ZipCode>088543925</ZipCode>
      <PhoneNumber>8489320150</PhoneNumber>
      <StreetAddress>33 Knightsbridge Road</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>New Jersey</StateName>
      <StateCode>NJ</StateCode>
    </Institution>
    <ProgramElement>
      <Code>7513</Code>
      <Text>TUES-Type 1 Project</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>9178</Code>
      <Text>UNDERGRADUATE EDUCATION</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>SMET</Code>
      <Text>SCIENCE, MATH, ENG &amp; TECH EDUCATION</Text>
    </ProgramReference>
  </Award>
</rootTag>
