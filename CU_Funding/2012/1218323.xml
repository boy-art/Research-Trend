<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>SHF: Small:Energy-Optimized Memory Hierarchies</AwardTitle>
    <AwardEffectiveDate>07/01/2012</AwardEffectiveDate>
    <AwardExpirationDate>06/30/2015</AwardExpirationDate>
    <AwardAmount>400000</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05010000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Division of Computing and Communication Foundations</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Tao Li</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>The early 21st century finds power and energy as the central challenges to continued improvements in computer system performance and cost. From handheld mobile devices to the data centers that support them, computer architects must invent new energy-efficient techniques to facilitate future innovations in science, education, government and commerce. In current systems, the memory hierarchy-which stores and moves the data values used and produced by the computation-consumes more energy than the computation itself. For example, obtaining operands for a double-precision multiply-add can consume 1.7 to 200 times the operation's energy depending on where in the memory hierarchy the values are stored. Improving the energy-efficiency of memory hierarchies can not only enable advances in future computer systems, but also reduces the emission of greenhouse gases.&lt;br/&gt;&lt;br/&gt;This project seeks novel memory hierarchy designs that minimize power and energy, rather than the classical focus on reducing latency and/or bandwidth. These designs build on three key hypotheses: (1) cache memories can reduce energy more than either latency or bandwidth, (2) optimizing latency becomes less important when it can be tolerated, and (3) overlapping activity does not save power, but can save energy due to static power dissipation. Initial research directions include (1) a technique to reduce address translation energy using a hybrid virtual/physical cache that eliminates the need to access a highly-associative TLB on every memory access and (2) energy-efficient cache hierarchies that use data compression techniques to replace the high energy cost of misses with lower compression and decompression overheads. This research will also extend the widely-used open-source gem5 simulation infrastructure to more accurately model the power and energy of emerging memory hierarchies.</AbstractNarration>
    <MinAmdLetterDate>06/25/2012</MinAmdLetterDate>
    <MaxAmdLetterDate>06/25/2012</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1218323</AwardID>
    <Investigator>
      <FirstName>Mark</FirstName>
      <LastName>Hill</LastName>
      <EmailAddress>markhill@cs.wisc.edu</EmailAddress>
      <StartDate>06/25/2012</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>David</FirstName>
      <LastName>Wood</LastName>
      <EmailAddress>david@cs.wisc.edu</EmailAddress>
      <StartDate>06/25/2012</StartDate>
      <EndDate/>
      <RoleCode>Co-Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of Wisconsin-Madison</Name>
      <CityName>MADISON</CityName>
      <ZipCode>537151218</ZipCode>
      <PhoneNumber>6082623822</PhoneNumber>
      <StreetAddress>21 North Park Street</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Wisconsin</StateName>
      <StateCode>WI</StateCode>
    </Institution>
  </Award>
</rootTag>
