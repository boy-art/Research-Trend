<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>Collaborative Research: Time-Consistent Risk-Averse Control of Markov Systems</AwardTitle>
    <AwardEffectiveDate>09/01/2013</AwardEffectiveDate>
    <AwardExpirationDate>08/31/2016</AwardExpirationDate>
    <AwardAmount>169976</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>03040000</Code>
      <Directorate>
        <LongName>Direct For Mathematical &amp; Physical Scien</LongName>
      </Directorate>
      <Division>
        <LongName>Division Of Mathematical Sciences</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Michael H. Steuerwalt</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Ruszczynski, 1312016&lt;br/&gt;Dentcheva, 1311978&lt;br/&gt;&lt;br/&gt; The project is concerned with optimal control of multi-dimensional dynamic stochastic systems with risk aversion. Two approaches to risk aversion are considered: dynamic risk measures and stochastic orders. The investigators seek to advance their work on risk-averse discrete-time models and to develop general methodology for incorporating risk models into continuous-time optimal control problems of Markov structure. Three major challenges are associated with this project. First, the investigators develop proper mathematical tools for measuring risk in a time-consistent manner that would be suitable for continuous-time Markov systems. Second, the investigators develop optimality theory for control problems involving time-consistent dynamic models of risk. This includes the analysis of the structure of the control models, existence of solutions, and properties of the solutions. When developing risk-averse control models the third challenge has to be taken into account: the possibility to solve the problems numerically in an efficient way. &lt;br/&gt;&lt;br/&gt; Decision and control problems under uncertainty arise in many areas: energy production and distribution, telecommunication, insurance and finance, logistics, medicine, security and military applications. In most cases decisions have to be made over time: decisions, as well as the random environment, influence evolution of a system, which creates the need to make new decisions, etc. Therefore, a policy has to be designed that incorporates rules for responding to future states of the system. So far, most theoretical models of such control processes have been based on average performance criteria. The investigators propose to take into account risk, that is, the possibility of occurrence of highly undesirable scenarios. The project develops mathematical models for quantifying risk in dynamical systems that evolve in a continuous way. It also provides methods to determine the best policy, when risk aversion is essential.</AbstractNarration>
    <MinAmdLetterDate>09/11/2013</MinAmdLetterDate>
    <MaxAmdLetterDate>09/11/2013</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1311978</AwardID>
    <Investigator>
      <FirstName>Darinka</FirstName>
      <LastName>Dentcheva</LastName>
      <EmailAddress>darinka.dentcheva@stevens.edu</EmailAddress>
      <StartDate>09/11/2013</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Stevens Institute of Technology</Name>
      <CityName>HOBOKEN</CityName>
      <ZipCode>070305991</ZipCode>
      <PhoneNumber>2012168762</PhoneNumber>
      <StreetAddress>CASTLE POINT ON HUDSON</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>New Jersey</StateName>
      <StateCode>NJ</StateCode>
    </Institution>
    <ProgramElement>
      <Code>1266</Code>
      <Text>APPLIED MATHEMATICS</Text>
    </ProgramElement>
  </Award>
</rootTag>
