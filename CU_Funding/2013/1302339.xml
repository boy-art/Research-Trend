<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>HCC: Medium: Collaborative Research: Neural Control of Powered Artificial Legs</AwardTitle>
    <AwardEffectiveDate>06/15/2013</AwardEffectiveDate>
    <AwardExpirationDate>05/31/2017</AwardExpirationDate>
    <AwardAmount>628999</AwardAmount>
    <AwardInstrument>
      <Value>Continuing grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05020000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Information &amp; Intelligent Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Ephraim P. Glinert</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Recent breakthroughs in the mechatronics of powered lower limb (LL) prostheses hold the promise of enabling restoration for the large and growing population of lower limb amputees of a broad spectrum of functionality (e.g., standing up when seated in a chair, climbing stairs, and even running). The PIs argue that to realize this potential it is essential to provide neural control of artificial legs. The application of existing upper limb (UL) neural control approaches is inappropriate to this end, because the UL and LL neural control mechanisms are significantly different. In particular, most activities involving the lower limbs recruit both involuntary (spinal cord) and voluntary (supra-spinal) neural control, present high dynamics, and require multi-joint coordination and control of unstable locomotion, characteristics which combine to make the design specifications for neural control of LL prostheses much more demanding than those for UL devices. In this project the PIs will address this challenge by developing an innovative neural control system for powered artificial legs that can recognize and exploit multi-scale user intent (e.g., general motor commands such as intended task vs. detailed motor commands such as intended joint motion) to modulate intrinsic (autonomous) control of multiple LL prosthetic joints for locomotor and nonlocomotor task performance. The goals are to support reverse-engineering of the neural control of human locomotion while creating innovative neural-machine interfacing (NMI) technology that enables users to control the dynamics of LL prostheses in a natural, adaptive and flexible way. Inspired by what is currently known about the neurological organization and function of the human motor control system, the PIs' approach is to design a novel NMI based on a combination of noninvasive scalp electroencephalography (EEG) and surface electromyography (EMG). The hypothesis is that fusion of low-level peripheral and high-level central neural control sources can achieve multi-scale user intent recognition with higher accuracy and more rapid response time than can be realized with either EEG or EMG alone. A hierarchical control scheme for powered LL prostheses, in which multi-scale user intent identified by the NMI modulates intrinsic (autonomous) control, will support intuitive and efficient prosthesis use in dynamic, multi-joint coordinated movements while significantly reducing the mental burden of the prosthesis user in locomotion because the cyclic motion is achieved autonomously (this is desired because we rarely think about knee and ankle control when walking). The PIs will also explore correlation across EEG and EMG signals, which may provide insight into neural adaption and the time course of cortical control during the initiation and generation of gait, including how the brain initiates walking and regulates motor output in anticipation of key events such as foot placement at landing or during stepping up and down, weight acceptance, and push-off into swing phase. Finally, the PIs will use translational research to validate their novel approach in patients with trans-femoral amputations (a high and challenging amputation level).&lt;br/&gt;&lt;br/&gt;Broader Impacts: The PIs' long-term objective is to develop true bionic prostheses that feel and work just like real legs. Their approach in this project represents a paradigm shift in the control of lower limb wearable prosthetics. As such, project outcomes will directly impact both the Human-Robot Interaction and Brain-Machine Interface research communities. The findings will also be relevant to the neuroscience and rehabilitation communities, in that they will help elucidate the adaptive spinal cord and cortical contributions to human locomotion, while providing innovative and functional neuro-prosthetics solutions to improve the lives of lower limb amputees.</AbstractNarration>
    <MinAmdLetterDate>06/07/2013</MinAmdLetterDate>
    <MaxAmdLetterDate>05/11/2016</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1302339</AwardID>
    <Investigator>
      <FirstName>Jose</FirstName>
      <LastName>Contreras-Vidal</LastName>
      <EmailAddress>jlcontreras-vidal@uh.edu</EmailAddress>
      <StartDate>06/07/2013</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of Houston</Name>
      <CityName>Houston</CityName>
      <ZipCode>772042015</ZipCode>
      <PhoneNumber>7137435773</PhoneNumber>
      <StreetAddress>4800 Calhoun Boulevard</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Texas</StateName>
      <StateCode>TX</StateCode>
    </Institution>
    <ProgramElement>
      <Code>7367</Code>
      <Text>Cyber-Human Systems (CHS)</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>7367</Code>
      <Text>Cyber-Human Systems</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>7924</Code>
      <Text>MEDIUM PROJECT</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>9251</Code>
      <Text>RES EXPER FOR UNDERGRAD-SUPPLT</Text>
    </ProgramReference>
  </Award>
</rootTag>
