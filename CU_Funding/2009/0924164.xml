<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>Collaborative Research: Recovery of 3D Shapes from Single Views</AwardTitle>
    <AwardEffectiveDate>09/01/2009</AwardEffectiveDate>
    <AwardExpirationDate>08/31/2013</AwardExpirationDate>
    <AwardAmount>130479</AwardAmount>
    <AwardInstrument>
      <Value>Continuing grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>04040000</Code>
      <Directorate>
        <LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
      </Directorate>
      <Division>
        <LongName>Division Of Behavioral and Cognitive Sci</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Anne Cleary</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Collaborative Research: Recovery of 3D Shapes from Single Views&lt;br/&gt;&lt;br/&gt;Zygmunt Pizlo, Purdue University&lt;br/&gt;Longin Jan Latecki, Temple University&lt;br/&gt;&lt;br/&gt;The human eye, like a camera, produces 2-dimensional images of a 3-dimensional world. How does the human brain succeed in interpreting these impoverished 2-dimensional images, allowing us to see the world as it actually is "out there?" This fundamental question, whose significance has been appreciated for 300 years, has not been answered despite the efforts of many scientists, engineers and mathematicians. Conventional approaches, which have not been successful, tried to recover the 3-dimensional shapes of objects and scenes from their 2-dimensional images by analyzing the depths of surfaces in multiple images (such as might be obtained from two eyes or from moving images) and by emphasizing the role of learning and familiarity. The approach taken by Zygmunt Pizlo at Purdue University and Longin Jan Latecki at Temple University is very different. It uses only a single 2-D image to recover the third dimension by applying a priori constraints (assumptions about the world built-in to the human visual system) that reflect important visual properties that are generally present in the physical world, properties such as the symmetry and compactness of 3D objects. &lt;br/&gt;&lt;br/&gt;Pizlo and Latecki's research has the potential of encouraging theoretical changes in the study of human perception because it uses an entirely new approach to a classical unsolved problem in vision. It could support breakthroughs in machine vision because human beings are known to be much better than any machine confronted with recovering the 3D world from 2D information. Machine vision has important applications to many domains, including law enforcement and national security. Pizlo and Latecki's research attempts to solve the visual 3D shape problem by combining the results of experiments on human observers with state-of-the-art computational modeling. The project will provide an excellent opportunity for the interdisciplinary education of graduate and undergraduate students in psychology, computer science and engineering.</AbstractNarration>
    <MinAmdLetterDate>08/24/2009</MinAmdLetterDate>
    <MaxAmdLetterDate>07/07/2011</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>0924164</AwardID>
    <Investigator>
      <FirstName>Longin Jan</FirstName>
      <LastName>Latecki</LastName>
      <EmailAddress>latecki@temple.edu</EmailAddress>
      <StartDate>08/24/2009</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Temple University</Name>
      <CityName>PHILADELPHIA</CityName>
      <ZipCode>191405104</ZipCode>
      <PhoneNumber>2157077379</PhoneNumber>
      <StreetAddress>3340 N. Broad Street</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Pennsylvania</StateName>
      <StateCode>PA</StateCode>
    </Institution>
    <ProgramElement>
      <Code>7252</Code>
      <Text>PERCEPTION, ACTION &amp; COGNITION</Text>
    </ProgramElement>
    <ProgramElement>
      <Code>7495</Code>
      <Text>ROBUST INTELLIGENCE</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>0000</Code>
      <Text>UNASSIGNED</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>OTHR</Code>
      <Text>OTHER RESEARCH OR EDUCATION</Text>
    </ProgramReference>
  </Award>
</rootTag>
