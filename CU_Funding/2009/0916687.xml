<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>RI: SMALL: Category-Driven Affordance Prediction For Autonomous Robots</AwardTitle>
    <AwardEffectiveDate>07/15/2009</AwardEffectiveDate>
    <AwardExpirationDate>02/28/2014</AwardExpirationDate>
    <AwardAmount>449063</AwardAmount>
    <AwardInstrument>
      <Value>Continuing grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05020000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Information &amp; Intelligent Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Jeffrey Trinkle</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>This research program is developing theory and algorithms that will enable a robot to learn through training and experimentation how to predict object and environmental affordances from sensor data. These affordances determine which actions a robot may perform when interacting with a given object, and thus define the capabilities of the robot at any given time. For example, a doorway affords the possibility to leave one room and enter another, and a handle attached to an object affords the ability to grasp it. The approach being developed leverages a graphical model approach to learn visual categories ? to learn the world contains entities such as doors and handles ? that provide a powerful intermediate representation for affordance prediction and learning. This is in contrast to the classical direct perception approach in which the agent learns a direct mapping from image features to affordances. The models and theory are being validated on two robot platforms and tasks: an outdoor mobile robot performing navigation and pursuit/evasion tasks, and an indoor robot manipulator performing assembly/disassembly tasks.&lt;br/&gt;&lt;br/&gt;The importance and broader impact of this research lies in empowering robots to actively and effectively learn about its environment given little human training. Because pre-programmed sensing capabilities are typically brittle ? not accounting for the variability of the world in which the robot is actually operating ? and because extensive human training and supervision is too labor intensive, such learning paradigms are essential for the development of robots that operate effectively in the human world.</AbstractNarration>
    <MinAmdLetterDate>07/10/2009</MinAmdLetterDate>
    <MaxAmdLetterDate>07/29/2011</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>0916687</AwardID>
    <Investigator>
      <FirstName>Aaron</FirstName>
      <LastName>Bobick</LastName>
      <EmailAddress>afb@wustl.edu</EmailAddress>
      <StartDate>07/10/2009</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>James</FirstName>
      <LastName>Rehg</LastName>
      <EmailAddress>rehg@cc.gatech.edu</EmailAddress>
      <StartDate>07/10/2009</StartDate>
      <EndDate/>
      <RoleCode>Co-Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Georgia Tech Research Corporation</Name>
      <CityName>Atlanta</CityName>
      <ZipCode>303320420</ZipCode>
      <PhoneNumber>4048944819</PhoneNumber>
      <StreetAddress>Office of Sponsored Programs</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Georgia</StateName>
      <StateCode>GA</StateCode>
    </Institution>
    <ProgramElement>
      <Code>7495</Code>
      <Text>ROBUST INTELLIGENCE</Text>
    </ProgramElement>
    <ProgramElement>
      <Code>7453</Code>
      <Text>GRAPHICS &amp; VISUALIZATION</Text>
    </ProgramElement>
    <ProgramElement>
      <Code>7364</Code>
      <Text>INFO INTEGRATION &amp; INFORMATICS</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>7495</Code>
      <Text>ROBUST INTELLIGENCE</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>7923</Code>
      <Text>SMALL PROJECT</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>9215</Code>
      <Text>HIGH PERFORMANCE COMPUTING SYSTEMS</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>HPCC</Code>
      <Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>7364</Code>
      <Text>INFO INTEGRATION &amp; INFORMATICS</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>7453</Code>
      <Text>GRAPHICS &amp; VISUALIZATION</Text>
    </ProgramReference>
  </Award>
</rootTag>
