<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>Understanding Attention Switching with Visual and Audio Cues in Time-Safety Critical Situations</AwardTitle>
    <AwardEffectiveDate>10/01/2009</AwardEffectiveDate>
    <AwardExpirationDate>09/30/2011</AwardExpirationDate>
    <AwardAmount>80000</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05020000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Information &amp; Intelligent Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Jie Yang</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>This project utilizes a holistic, human-centered approach in the design of intelligent driver support systems, where situational criticality estimates are continuously monitored. This requires computational models for accurate estimation of how a driver perceives situations, plans actions, and reacts and interacts with the vehicle and its surround. The specific goal of the project is to develop computational frameworks to analyze attention shifts, using multimodal cues, in an environment where time and safety constraints are critical. Specific research objectives are: (1) Identification of body related indicators of attention switching. This involves utilizing statistical machine-learning algorithms to analyze previously collected ethnographic datasets and determine most useful indicators of attention shifts, including head and eye gaze, hands, feet, and other body motions. (2) Understanding the effect of external visual and audio saliency cues in the driving environment on attention shifts. This involves the analysis of how those multimodal cues affect attention shifts in time- and safety-critical situations, incorporating ?top-down? goal-oriented and ?bottom-up? distraction-based mechanisms. (3) Developing a hierarchical Bayesian model and computational framework for describing the relationship between body cues, external saliency, and driving task, in order to accurately estimate attention and attention shifts. In summary, the project provides a feasibility assessment of detecting how and why attention shifts occur in the vehicular environment with a multimodal sensor suite. Project findings will influence design of active safety systems to reduce crash risk on the roads.</AbstractNarration>
    <MinAmdLetterDate>09/21/2009</MinAmdLetterDate>
    <MaxAmdLetterDate>09/21/2009</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>0958033</AwardID>
    <Investigator>
      <FirstName>Mohan</FirstName>
      <LastName>Trivedi</LastName>
      <EmailAddress>trivedi@ece.ucsd.edu</EmailAddress>
      <StartDate>09/21/2009</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of California-San Diego</Name>
      <CityName>La Jolla</CityName>
      <ZipCode>920930621</ZipCode>
      <PhoneNumber>8585344896</PhoneNumber>
      <StreetAddress>Office of Contract &amp; Grant Admin</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>California</StateName>
      <StateCode>CA</StateCode>
    </Institution>
    <ProgramElement>
      <Code>7495</Code>
      <Text>ROBUST INTELLIGENCE</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>7495</Code>
      <Text>ROBUST INTELLIGENCE</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>9215</Code>
      <Text>HIGH PERFORMANCE COMPUTING SYSTEMS</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>HPCC</Code>
      <Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
    </ProgramReference>
  </Award>
</rootTag>
