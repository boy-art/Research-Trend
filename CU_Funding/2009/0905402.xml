<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>RI: Medium: Collaborative Research: Physically Grounded Object Recognition</AwardTitle>
    <AwardEffectiveDate>07/01/2009</AwardEffectiveDate>
    <AwardExpirationDate>06/30/2013</AwardExpirationDate>
    <AwardAmount>798981</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05020000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Information &amp; Intelligent Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Kenneth C. Whang</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5)."&lt;br/&gt;&lt;br/&gt;Although the world is very much three-dimensional, most of today's approaches to visual object recognition essentially reduce the problem to one of 2D pattern classification, where rectangular image patches are independently compared to stored templates to produce isolated object labels within the image. This project aims to account for the three-dimensional nature of the real world by exploring qualitative geometric reasoning in terms of 3D spatial relationships between scene components, category-level object models, and global scene understanding.&lt;br/&gt;&lt;br/&gt;The project is organized around two major research areas. Qualitative 3D scene parsing: A central part of our effort will be to develop qualitative 3D models of the scene that describe the depicted objects and surfaces and their physical relations. Grounding objects in the scene: We integrate the geometric representation of the scene and the corresponding 3D spatial relations with the object recognition process by (1) inferring the set of likely object identities based on 3D relations among scene components; (2) predicting the most likely object locations from the scene layout; and (3) using the occlusion relations and depth ordering to predict the parts of objects that may be visible in the scene.&lt;br/&gt;&lt;br/&gt;The project is anticipated to result in major advances in 3D scene understanding from photographs, a critical enabling technology for a wide range of applications including autonomous systems, health care, human-computer interaction, assistive technology, image retrieval, industrial and personal robotics, manufacturing, scientific image analysis, surveillance and security, and transportation.</AbstractNarration>
    <MinAmdLetterDate>06/22/2009</MinAmdLetterDate>
    <MaxAmdLetterDate>02/29/2012</MaxAmdLetterDate>
    <ARRAAmount>798981</ARRAAmount>
    <AwardID>0905402</AwardID>
    <Investigator>
      <FirstName>Alexei</FirstName>
      <LastName>Efros</LastName>
      <EmailAddress>efros@eecs.berkeley.edu</EmailAddress>
      <StartDate>06/22/2009</StartDate>
      <EndDate/>
      <RoleCode>Co-Principal Investigator</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>Martial</FirstName>
      <LastName>Hebert</LastName>
      <EmailAddress>martial.Hebert@cs.cmu.edu</EmailAddress>
      <StartDate>06/22/2009</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Carnegie-Mellon University</Name>
      <CityName>PITTSBURGH</CityName>
      <ZipCode>152133815</ZipCode>
      <PhoneNumber>4122689527</PhoneNumber>
      <StreetAddress>5000 Forbes Avenue</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Pennsylvania</StateName>
      <StateCode>PA</StateCode>
    </Institution>
  </Award>
</rootTag>
