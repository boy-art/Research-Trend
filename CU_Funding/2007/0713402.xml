<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>RI: Collaborative Research: Discriminative Knowledge-Rich Language Modeling for Machine Translation</AwardTitle>
    <AwardEffectiveDate>09/01/2007</AwardEffectiveDate>
    <AwardExpirationDate>08/31/2012</AwardExpirationDate>
    <AwardAmount>390214</AwardAmount>
    <AwardInstrument>
      <Value>Continuing grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05020000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Information &amp; Intelligent Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Tatiana D. Korelsky</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>This project investigates a novel approach for assessing the fluency and&lt;br/&gt;grammaticality of alternative translation hypotheses that are created within&lt;br/&gt;search-based Machine Translation (MT) systems. This task, commonly termed&lt;br/&gt;"Language Modeling" (LM), has been explored primarily in the context of speech&lt;br/&gt;recognition; however, current state-of-the-art language models (LMs) are not&lt;br/&gt;effective at distinguishing between more fluent grammatical translations and&lt;br/&gt;their poor alternatives. In contrast, the proposed approach, "Discriminative&lt;br/&gt;Knowledge-Rich Language Modeling" (DKRLM), is explicitly designed to find the&lt;br/&gt;most fluent and grammatical translations within the search space by comparing&lt;br/&gt;the linguistic features of the translation hypotheses against very large&lt;br/&gt;"clean" monolingual corpora. The intuition is that more grammatical&lt;br/&gt;translation hypotheses should contain higher proportions of features seen in&lt;br/&gt;the large corpora. An important contribution of the project is in exploring&lt;br/&gt;different types of linguistic features to identify those that are most&lt;br/&gt;informative for the comparisons. Moreover, discriminative training is&lt;br/&gt;performed to incorporate the features into a system-independent scoring&lt;br/&gt;function, replacing traditional LMs in MT systems. The broader impacts of the&lt;br/&gt;proposed work include both broader adoption for the methodology as well as&lt;br/&gt;wider use of the new DKRLM functions to other search-based NLP applications&lt;br/&gt;that aim at generating fluent grammatical text. This includes search-based&lt;br/&gt;approaches to Speech Recognition, Natural Language Generation (NLG), Optical&lt;br/&gt;Character Recognition (OCR), Summarization, and others.</AbstractNarration>
    <MinAmdLetterDate>08/29/2007</MinAmdLetterDate>
    <MaxAmdLetterDate>09/21/2010</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>0713402</AwardID>
    <Investigator>
      <FirstName>Alon</FirstName>
      <LastName>Lavie</LastName>
      <EmailAddress>alavie@cs.cmu.edu</EmailAddress>
      <StartDate>08/29/2007</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Carnegie-Mellon University</Name>
      <CityName>PITTSBURGH</CityName>
      <ZipCode>152133815</ZipCode>
      <PhoneNumber>4122689527</PhoneNumber>
      <StreetAddress>5000 Forbes Avenue</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Pennsylvania</StateName>
      <StateCode>PA</StateCode>
    </Institution>
  </Award>
</rootTag>
