<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>SBIR Phase I: Visual Information Delivery Robot for Visually Impaired Children</AwardTitle>
    <AwardEffectiveDate>01/01/2010</AwardEffectiveDate>
    <AwardExpirationDate>12/31/2010</AwardExpirationDate>
    <AwardAmount>200000</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>07070000</Code>
      <Directorate>
        <LongName>Directorate For Engineering</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Industrial Innovation &amp; Partnersh</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Glenn H. Larsen</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>This Small Business Innovation Research (SBIR) Phase I project will evaluate the feasibility of a robotic system to detect and track a child's finger so that the scene that the child wishes to see can be displayed at high magnification on a monitor. There are two issues of intellectual merit that will be addressed during the Phase I work. The first issue is analyzing the pointing pattern of children. Since each person has his or her own pattern for raising an arm and pointing with a finger, the system requires a machine learning algorithm to adjust the decision from the system. This adaptive algorithm forms one of the key innovations that will be evaluated during the Phase I work. The second issue will be an adaptive zooming and scene segmentation algorithm. &lt;br/&gt;&lt;br/&gt;There are two primary commercial applications for the proposed visual information delivery robot. The first involves the education of visually impaired children. Most of research and products currently available for visually impaired children are focused on learning while they are sitting on the chair in front of the computer monitor. However, the proposed system captures the scene that the child points to in any location, thus bringing a dynamic tool to education. It is anticipated that such tools will have a significant commercial potential in schools for the visually impaired. The second commercial application is in assisting visually impaired adults with enhanced dynamic information when they are in a wheelchair. The commercial and societal impact of the proposed project is that it will enable visually impaired children and adults to enhance their quality of life by adding a dynamic tool for visualizing near and far off objects. The algorithms developed during the Phase I research will also aid researchers in industrial automation with advanced robots.</AbstractNarration>
    <MinAmdLetterDate>11/04/2009</MinAmdLetterDate>
    <MaxAmdLetterDate>06/07/2010</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>0945236</AwardID>
    <Investigator>
      <FirstName>Yudaya</FirstName>
      <LastName>Sivathanu</LastName>
      <EmailAddress>sivathan@enurga.com</EmailAddress>
      <StartDate>12/01/2009</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>Hyukseong</FirstName>
      <LastName>Kwon</LastName>
      <EmailAddress>hyukseon@purdue.edu</EmailAddress>
      <StartDate>11/04/2009</StartDate>
      <EndDate>12/01/2009</EndDate>
      <RoleCode>Former Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>EN'URGA INC</Name>
      <CityName>WEST LAFAYETTE</CityName>
      <ZipCode>479061359</ZipCode>
      <PhoneNumber>7654973269</PhoneNumber>
      <StreetAddress>1201 CUMBERLAND AVE, Suite R</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Indiana</StateName>
      <StateCode>IN</StateCode>
    </Institution>
    <FoaInformation>
      <Code>0308000</Code>
      <Name>Industrial Technology</Name>
    </FoaInformation>
  </Award>
</rootTag>
