<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>EAGER: Preliminary Investigation of Virtual Tactual Stereognosis</AwardTitle>
    <AwardEffectiveDate>07/01/2009</AwardEffectiveDate>
    <AwardExpirationDate>06/30/2011</AwardExpirationDate>
    <AwardAmount>154250</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05020000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Information &amp; Intelligent Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Ephraim P. Glinert</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Imagine reaching into your pocket, locating and grasping your car;'s key fob amongst a clutter of coins, bills and keys, then finding the unlock button (not the lock button, not the trunk release, especially not the panic button) and pressing it. This is an example of Tactual Stereognosis (TS), the ability of people to identify familiar items using touch alone. It is commonplace and uneventful. Yet no programmable haptic interface has ever been developed that would allow people to identify virtual objects using what might be termed Virtual Tactual Stereognosis (VTS). Creating such an interface is a long-range goal of the PIs. VTS has long been out of reach because it depends on active touch, multi-finger interaction, and bare fingertips, which are all difficult to achieve with existing display technology. The PIs' recent research has led to a new class of prototype devices (xPaDs), which address each of these limitations. These devices use friction modulation to control forces between the fingertip and a flat plate. The basic TPaD (Tactile Pattern Display) can create effects such as virtual textures, virtual bumps and holes, and more. More advanced versions such as the ShiverPad and SwirlPad synchronize in-plane vibrations to friction levels in order to generate active pushing forces on the fingertip. It is possible to generate many additional effects with these devices, including virtual edges that can be traced with the fingertip. The xPaD devices thus appear to be well suited to VTS. They are active touch devices that work with bare fingertips (in other words, the xPaD is fixed and the finger slides over it). Moreover, they are very compact, potentially enabling multiple panels to be arrayed over the surface of an object in order to support a multi-finger interface. In this study the PIs will begin exploration of a multi-xPaD interface, by performing experiments on an interface consisting of two opposing ShiverPads with subjects employing a pinch grip (that is, index finger on one ShiverPaD, and thumb on the other), in order to demonstrate "binding," the perceptual fusion of the finger and thumb percepts into an integrated object representation.&lt;br/&gt;&lt;br/&gt;Broader Impacts: Virtual Tactual Stereognosis is an important goal for many reasons. Graphical displays have become an important form of interface in venues ranging from the living room, to the office, to the car, to any place that a person may be. Yet as graphical displays grow more prevalent, natural touch interactions seemingly grow more obsolete. VTS aims to achieve the opposite, to empower future interfaces with sophisticated tactual capabilities that engage perceptual as well as sensory mechanisms in the hand and brain. Imagine a doctor able to simultaneously look at and palpate tissue within the body, a pregnant mother able to caress the ultrasound image of her unborn child, an autistic child able to cooperate with an animated character in a construction task, or a driver able to reach out, find and operate touch screen controls without taking his/her eyes off the road. VTS would be an enabler for new types of electronic displays for the blind. And it would be a powerful new tool to extend our basic knowledge of haptic perception as it occurs naturally.</AbstractNarration>
    <MinAmdLetterDate>07/02/2009</MinAmdLetterDate>
    <MaxAmdLetterDate>05/18/2010</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>0941581</AwardID>
    <Investigator>
      <FirstName>Michael</FirstName>
      <LastName>Peshkin</LastName>
      <EmailAddress>peshkin@northwestern.edu</EmailAddress>
      <StartDate>07/02/2009</StartDate>
      <EndDate/>
      <RoleCode>Co-Principal Investigator</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>J. Edward</FirstName>
      <LastName>Colgate</LastName>
      <EmailAddress>colgate@northwestern.edu</EmailAddress>
      <StartDate>07/02/2009</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Northwestern University</Name>
      <CityName>Evanston</CityName>
      <ZipCode>602013149</ZipCode>
      <PhoneNumber>8474913003</PhoneNumber>
      <StreetAddress>1801 Maple Ave.</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Illinois</StateName>
      <StateCode>IL</StateCode>
    </Institution>
    <ProgramElement>
      <Code>7367</Code>
      <Text>Cyber-Human Systems (CHS)</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>7367</Code>
      <Text>Cyber-Human Systems</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>7916</Code>
      <Text>EAGER</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>9215</Code>
      <Text>HIGH PERFORMANCE COMPUTING SYSTEMS</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>9251</Code>
      <Text>RES EXPER FOR UNDERGRAD-SUPPLT</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>HPCC</Code>
      <Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
    </ProgramReference>
  </Award>
</rootTag>
