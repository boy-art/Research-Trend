<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>EAGER: RI: Developing a Framework for Automated Measurement of the Intensity of Spontaneous Facial Expressions</AwardTitle>
    <AwardEffectiveDate>11/01/2009</AwardEffectiveDate>
    <AwardExpirationDate>10/31/2011</AwardExpirationDate>
    <AwardAmount>87886</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05020000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Information &amp; Intelligent Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Jie Yang</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Spontaneous facial expressions are representative of facial expressions in daily life. Studying spontaneous (non-posed) facial expressions and Facial Action Coding System-AUs (FACS-AUs) requires spontaneous face expression data where the action units are manually and reliably coded. Currently, there is a high demand in computer vision society for such a database. The first objective of this research is to capture a 3D facial expression database and make it publically available to others interested in studying spontaneous facial expressions. As ground-truth, we also manually code the existence and the intensity of important action units (i.e., AU 1, 2, 4, 6, 9, 10, 12, 14, 15, 20, 25, and 26) in this dataset. These action units describe positive and negative emotional expressions. &lt;br/&gt;&lt;br/&gt;The second objective of this research is to develop a framework to automatically measure the intensity of spontaneous FACS action units in videos captured from adults? faces. We aim to study dictionary-based representation (e.g., combination of wavelet and shearlet) to model face appearance in facial images. This is due to the fact that human facial images contain of edges, wrinkles and texture. We study this type of combined representations to provide a sparse representation of images containing edges and textures and utilize it in measuring the AU intensities. &lt;br/&gt;&lt;br/&gt;The results of this research, the face database, the manually codes of AUs, and the developed framework in the measuring the AUs, are made publically available to other researchers in computer vision society.</AbstractNarration>
    <MinAmdLetterDate>09/23/2009</MinAmdLetterDate>
    <MaxAmdLetterDate>03/22/2011</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>0957983</AwardID>
    <Investigator>
      <FirstName>Mohammad</FirstName>
      <LastName>Mahoor</LastName>
      <EmailAddress>mmahoor@du.edu</EmailAddress>
      <StartDate>09/23/2009</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of Denver</Name>
      <CityName>Denver</CityName>
      <ZipCode>802104711</ZipCode>
      <PhoneNumber>3038712000</PhoneNumber>
      <StreetAddress>2199 S. University Blvd.</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Colorado</StateName>
      <StateCode>CO</StateCode>
    </Institution>
  </Award>
</rootTag>
