<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>MRI: Development of a Next-Generation Multimodal Data Management Human-Sensing Instrument for Trustworthy Research Collaboration and Quality of Life Improvement</AwardTitle>
    <AwardEffectiveDate>10/01/2009</AwardEffectiveDate>
    <AwardExpirationDate>09/30/2013</AwardExpirationDate>
    <AwardAmount>770622</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05050000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Division Of Computer and Network Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Rita V. Rodriguez</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Proposal #: CNS 09-23494 &lt;br/&gt;PI(s): Makedon, Fillia S.; Athitsos, Vassilis; Huang, Heng; Le, Zhengyi; Popa, Dan O.&lt;br/&gt;Institution: University of Texas - Arlington&lt;br/&gt;Title: MRI/Dev.: Next Generation Multimodal Data Management Human-Sensing Instrument for &lt;br/&gt; Trustworthy Research Collaboration and Quality of Life Improvement&lt;br/&gt;Project Proposed:&lt;br/&gt;This project, developing an instrument that serves as an interactive personal care and human activity monitoring center, aims to keep a person with high quality life and safe at home as long as possible. The instrument enables privacy-preserving and secure data sharing through wireless connection with remote users in an assistive living environment. Providing mental and emotional support, the zooscopion (zScope) can connect devices, humans, objects, and the environment. It can connect to other assistive living projects, making them interoperable and can deliver a Digital Library of sanitized research data and cases with high educational and training value. zScope combines and correlates many types of data and extracts events of interest that indicate changes, risks, etc. It can analyze facial expressions to detect pain, environmental data, house data (such as door opening, telephone sounds, vacuum cleaner, etc.), human performance metrics (e.g., hand strength), both in continuous and discrete format. Data are modeled and assembled in meaningful ways to predict and prevent physical and digital problems (e.g., respectively, falls and intrusions). Privacy and security are being made part of the data modeling at the design phase. The instrument will take sensor data, human body measurements, camera data when requested, known pattern of behavior from other cases, brain scans, and clinical information, aiming to provide high resolution displays of longitudinal as well as episodic events. It outputs a visual interactive display of patterns and significant human behavioral 'events' valuable in assistive environments, setting where to use non-invasive monitoring technologies, helping recognize 'behavioral biomarkers' that will be connected to other types of health indicators that may come from brain imaging, genetic analysis, clinical results, or psychological evaluations. It will work with the next generation of data that include behavioral, clinical, body motion, etc., and have low latency tracking. &lt;br/&gt;Broader Impacts: &lt;br/&gt;This work enables human-centric type of experiments and provides novel new ways of interaction, visualization, and secure collaboration. Developing 'smarter' living environments for the aged opens new ways to education with immersive compelling projects that provide a better understanding of the role of science and engineering when combining health data (genomic information) to behavior, predict trends, and provide indicators of how medication and clinical assessments connect to longitudinal behavior. Long term goals include behavioral markers for assessing the confluence of environment, drugs, and human psychology. The instrument is also expected to respond to queries regarding emerging needs for new analysis of collected information. It includes training and educational modules with search and browsing tools and a recommender facility to support decision making and use stored strategies. Moreover, utilizing existing outreach programs, the project will support local minority students and high school students A new generation of scientists that can work together across domain silos towards human centered goals might be in the making!</AbstractNarration>
    <MinAmdLetterDate>09/29/2009</MinAmdLetterDate>
    <MaxAmdLetterDate>04/15/2013</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>0923494</AwardID>
    <Investigator>
      <FirstName>Zhengyi</FirstName>
      <LastName>Le</LastName>
      <EmailAddress>zyle@uta.edu</EmailAddress>
      <StartDate>09/29/2009</StartDate>
      <EndDate/>
      <RoleCode>Co-Principal Investigator</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>Heng</FirstName>
      <LastName>Huang</LastName>
      <EmailAddress>heng@uta.edu</EmailAddress>
      <StartDate>09/29/2009</StartDate>
      <EndDate/>
      <RoleCode>Co-Principal Investigator</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>Vassilis</FirstName>
      <LastName>Athitsos</LastName>
      <EmailAddress>athitsos@uta.edu</EmailAddress>
      <StartDate>09/29/2009</StartDate>
      <EndDate/>
      <RoleCode>Co-Principal Investigator</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>Dan</FirstName>
      <LastName>Popa</LastName>
      <EmailAddress>dan.popa@louisville.edu</EmailAddress>
      <StartDate>09/29/2009</StartDate>
      <EndDate/>
      <RoleCode>Co-Principal Investigator</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>Fillia</FirstName>
      <LastName>Makedon</LastName>
      <EmailAddress>makedon@cse.uta.edu</EmailAddress>
      <StartDate>09/29/2009</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of Texas at Arlington</Name>
      <CityName>Arlington</CityName>
      <ZipCode>760190145</ZipCode>
      <PhoneNumber>8172722105</PhoneNumber>
      <StreetAddress>1 UNIVERSITY OF TEXAS AT</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Texas</StateName>
      <StateCode>TX</StateCode>
    </Institution>
    <FoaInformation>
      <Code>0000912</Code>
      <Name>Computer Science</Name>
    </FoaInformation>
    <ProgramElement>
      <Code>1189</Code>
      <Text>MAJOR RESEARCH INSTRUMENTATION</Text>
    </ProgramElement>
    <ProgramElement>
      <Code>1640</Code>
      <Text>INFORMATION TECHNOLOGY RESEARC</Text>
    </ProgramElement>
    <ProgramElement>
      <Code>1714</Code>
      <Text>SPECIAL PROJECTS - CISE</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>1189</Code>
      <Text>MAJOR RESEARCH INSTRUMENTATION</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>9102</Code>
      <Text>WOMEN, MINORITY, DISABLED, NEC</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>9178</Code>
      <Text>UNDERGRADUATE EDUCATION</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>9218</Code>
      <Text>BASIC RESEARCH &amp; HUMAN RESORCS</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>9251</Code>
      <Text>RES EXPER FOR UNDERGRAD-SUPPLT</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>HPCC</Code>
      <Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
    </ProgramReference>
  </Award>
</rootTag>
