<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>Supercomputing on a Cluster of Workstations via Scalable Locality and Scalable Parallelism</AwardTitle>
    <AwardEffectiveDate>09/15/2009</AwardEffectiveDate>
    <AwardExpirationDate>02/28/2013</AwardExpirationDate>
    <AwardAmount>129661</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05010000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Division of Computing and Communication Foundations</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Almadena Y. Chtchelkanova</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Modern scientific research often includes a substantial computational component, which may use a supercomputer and special software to automatically tune ("optimize") the application for the computer. A cluster of standard workstations can offer similar net processing power at a fraction of the cost, but automatic optimization of some important numerical applications for these systems remains an elusive challenge.&lt;br/&gt;The quest for good performance of parallel applications on clusters of workstations has traditionally employed software techniques that are quite different from those applied to the programming of parallel supercomputers. In particular, static automatic parallelization has been employed on supercomputers (especially for dense matrix codes on shared memory systems) but has not been successful on clusters. The lack of success with static parallelization is due in part to the inability of classic parallelization techniques to expose sufficient memory locality.&lt;br/&gt;&lt;br/&gt;The PI proposes to develop compiler techniques that will allow dense matrix problems to run efficiently on clusters of workstations by dramatically increasing locality while respecting the parallelism constraints of the code. The PI plans to investigate techniques for automatically producing high performance for dense matrix codes executing on clusters of workstations by "tiling" time-skewed loop nests such that they can execute efficiently on a cluster of multicore workstations. This research will enable automatic program optimization for numerical applications. The proposed activity could advance the state of performance models for tiling for clusters.</AbstractNarration>
    <MinAmdLetterDate>09/02/2009</MinAmdLetterDate>
    <MaxAmdLetterDate>04/11/2012</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>0943455</AwardID>
    <Investigator>
      <FirstName>David</FirstName>
      <LastName>Wonnacott</LastName>
      <EmailAddress>davew@cs.haverford.edu</EmailAddress>
      <StartDate>09/02/2009</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Haverford College</Name>
      <CityName>Haverford</CityName>
      <ZipCode>190411336</ZipCode>
      <PhoneNumber>6108961000</PhoneNumber>
      <StreetAddress>370 Lancaster Avenue</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Pennsylvania</StateName>
      <StateCode>PA</StateCode>
    </Institution>
    <FoaInformation>
      <Code>0000912</Code>
      <Name>Computer Science</Name>
    </FoaInformation>
    <ProgramElement>
      <Code>7329</Code>
      <Text>COMPILERS</Text>
    </ProgramElement>
    <ProgramElement>
      <Code>7798</Code>
      <Text>SOFTWARE &amp; HARDWARE FOUNDATION</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>7329</Code>
      <Text>COMPILERS</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>9218</Code>
      <Text>BASIC RESEARCH &amp; HUMAN RESORCS</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>9229</Code>
      <Text>RES IN UNDERGRAD INST-RESEARCH</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>9251</Code>
      <Text>RES EXPER FOR UNDERGRAD-SUPPLT</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>HPCC</Code>
      <Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
    </ProgramReference>
  </Award>
</rootTag>
