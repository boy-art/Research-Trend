<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>HCC: Medium: Collaborative Research: Development of Trust Models and Metrics for Human-Robot Interaction</AwardTitle>
    <AwardEffectiveDate>09/01/2009</AwardEffectiveDate>
    <AwardExpirationDate>08/31/2014</AwardExpirationDate>
    <AwardAmount>339000</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05020000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Information &amp; Intelligent Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Ephraim P. Glinert</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>It is often assumed that the use of robots to help people execute tasks will result in better performance than if the person or robot were operating alone. However, research in automated systems suggests that the performance of a human-machine system depends on the extent to which the person trusts the machine and the extent to which this trust (or distrust) is justified. As robots are being developed to aid people with complex tasks, it is critical not only that we build systems which people can trust, but that these systems also foster an appropriate level of trust based on the capabilities of the systems. A user who does not have an appropriate level of trust in the robot may misuse or abuse the robot's autonomous capabilities or expose people to danger. This project proposes to develop quantitative metrics to measure a user's trust in a robot as well as a model to estimate the user's level of trust in real time. Using this information, the robot will be able to adjust its interaction accordingly. &lt;br/&gt;&lt;br/&gt;Promoting appropriate levels of trust will be particularly beneficial in safety-critical domains such as urban search and rescue and assistive robotics, in which users risk harm to themselves, the robot, or the environment if users do not trust the robot enough to rely on its autonomous capabilities. The research has the potential for a large impact on the field of human-robot interaction as few studies have explicitly examined issues involving trust of robots. Being able to model trust and foster appropriate levels of trust will result in more effective use of robotic automation, safer interactions, and better task performance.</AbstractNarration>
    <MinAmdLetterDate>09/15/2009</MinAmdLetterDate>
    <MaxAmdLetterDate>04/06/2011</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>0905148</AwardID>
    <Investigator>
      <FirstName>Aaron</FirstName>
      <LastName>Steinfeld</LastName>
      <EmailAddress>steinfeld@cmu.edu</EmailAddress>
      <StartDate>09/15/2009</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Carnegie-Mellon University</Name>
      <CityName>PITTSBURGH</CityName>
      <ZipCode>152133815</ZipCode>
      <PhoneNumber>4122689527</PhoneNumber>
      <StreetAddress>5000 Forbes Avenue</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Pennsylvania</StateName>
      <StateCode>PA</StateCode>
    </Institution>
    <FoaInformation>
      <Code>0116000</Code>
      <Name>Human Subjects</Name>
    </FoaInformation>
  </Award>
</rootTag>
