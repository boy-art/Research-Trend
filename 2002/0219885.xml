<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>ITR: Learning and Measuring Perceptual Similarity</AwardTitle>
    <AwardEffectiveDate>08/15/2002</AwardEffectiveDate>
    <AwardExpirationDate>07/31/2005</AwardExpirationDate>
    <AwardAmount>161080</AwardAmount>
    <AwardInstrument>
      <Value>Continuing grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05020000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Information &amp; Intelligent Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Maria Zemankova</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Image retrieval has been an active research area for many years, but&lt;br/&gt;two fundamental problems remain largely unsolved: 1) How best to&lt;br/&gt;learn users' subjective query concepts, and 2) How to measure perceptual&lt;br/&gt;similarity with significant accuracy. The first problem concerns the&lt;br/&gt;completeness of formulating a query concept, e.g., how to formulate a&lt;br/&gt;query such as ``animals,'' ``cathedrals,'' or ``aircraft.'' The second&lt;br/&gt;problem concerns search accuracy, i.e., given a learned query concept,&lt;br/&gt;how to find all images that match that concept.&lt;br/&gt;&lt;br/&gt;To tackle these two fundamental problems and to ensure that our&lt;br/&gt;solutions are scalable, this project has four specific targets.&lt;br/&gt;First, we plan to develop novel active learning algorithms that&lt;br/&gt;quickly learn users' subjective query concepts (thoughts and intents)&lt;br/&gt;despite time and sample constraints. Second, we will design&lt;br/&gt;semi-automatic image annotation and annotation refinement methods&lt;br/&gt;for assigning semantic labels to images in order to support multimodality&lt;br/&gt;query-concept learning and information retrieval. Third, we will&lt;br/&gt;devise perceptual distance functions for improving accuracy of visual&lt;br/&gt;searches. For instance, once a query concept such as ``enemy vessels''&lt;br/&gt;is learned, we want to find every matching object in the surveillance&lt;br/&gt;database, not missing any. Finally, we plan to conduct validation&lt;br/&gt;studies} on developed learning algorithms, using experimental data&lt;br/&gt;provided by colleagues at various institutions (including IBM research&lt;br/&gt;centers and Fine Arts Museums of San Francisco).</AbstractNarration>
    <MinAmdLetterDate>08/07/2002</MinAmdLetterDate>
    <MaxAmdLetterDate>05/03/2004</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>0219885</AwardID>
    <Investigator>
      <FirstName>Edward</FirstName>
      <LastName>Chang</LastName>
      <EmailAddress>echang@ece.ucsb.edu</EmailAddress>
      <StartDate>08/07/2002</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of California-Santa Barbara</Name>
      <CityName>SANTA BARBARA</CityName>
      <ZipCode>931062050</ZipCode>
      <PhoneNumber>8058934188</PhoneNumber>
      <StreetAddress>Office of Research</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>California</StateName>
      <StateCode>CA</StateCode>
    </Institution>
    <FoaInformation>
      <Code>0104000</Code>
      <Name>Information Systems</Name>
    </FoaInformation>
  </Award>
</rootTag>
