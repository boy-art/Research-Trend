<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>Assessing Student Transfer and Retention of Learning in Mathematics, Physics, and Engineering Courses</AwardTitle>
    <AwardEffectiveDate>07/15/2002</AwardEffectiveDate>
    <AwardExpirationDate>06/30/2007</AwardExpirationDate>
    <AwardAmount>500000</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>11040200</Code>
      <Directorate>
        <LongName>Direct For Education and Human Resources</LongName>
      </Directorate>
      <Division>
        <LongName>Division Of Undergraduate Education</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Myles G. Boylan</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>This project is based on the theme that assessment is most useful when it is closest to instruction, in both form and time. Summative assessments at the end of a program provide necessary feedback, but are often of limited value in guiding improved achievement. Such assessment takes place several years after instruction in basic concepts and changes in instructors and instruction during the intervening time may make the feedback appear irrelevant. In addition, faculty members are often distrustful of reports where the faculty members lack first hand knowledge of the assessment procedure. To be most effective in improving design and conduct of actual courses, the instructors in the course should use the assessment tools themselves, preferably during the conduct of the course. Because the main reason for STEM majors taking core engineering science courses is to prepare them for future courses, the most important aspect of assessment is the ability of students to transfer their learning to new contexts in later courses. Assessment should not only serve the purpose of the instructor or the institution it should also aid the students in recognizing their own achievements and in guiding the students to improve their understanding. The goal of this project is to design online assessment tools that can be easily integrated into core engineering science courses and that are capable of answering the following questions:&lt;br/&gt; What specific material have the students learned in core engineering science courses in mathematics and physics?&lt;br/&gt; What understanding do the students have of the material they have learned? Is it just disconnected facts and procedures, a broad conceptual picture informed by careful understanding of the details, or something in between? If it is something in between, can we describe more exactly what understanding they have gained?&lt;br/&gt; How much (and what type of) knowledge do the students retain after specific classes have ended.&lt;br/&gt; Can the students use the material they have learned in new situations in their professional courses? How consistently do they use the understanding developed in core engineering science courses when encountering these ideas in new contexts? In the best case, can we predict in advance whether students have gained the necessary understanding to successfully apply their knowledge in new contexts?&lt;br/&gt;Early versions of the sought after assessment tools have been developed under an earlier grant: "Technology &amp; Model- Based Conceptual Assessment: Research on Students Applications of Models in Physics and Mathematics" funded by the NSF ROLE program (REC-0087788). Model Analysis is being used to develop and validate the tools. These tools are providing great insight into student conceptual understanding and learning styles, and this project is expanding their use to more core classes, and extending the focus from basic research on student learning to assessment of learning and conceptual understanding. The assessment tools we are developing are providing real-time feedback to both instructors and students, enabling both to adjust the teaching and learning process to improve student achievement in terms of conceptual understanding and the ability to transfer learning to new contexts.</AbstractNarration>
    <MinAmdLetterDate>07/11/2002</MinAmdLetterDate>
    <MaxAmdLetterDate>07/11/2002</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>0206943</AwardID>
    <Investigator>
      <FirstName>N. Sanjay</FirstName>
      <LastName>Rebello</LastName>
      <EmailAddress>rebellos@purdue.edu</EmailAddress>
      <StartDate>07/11/2002</StartDate>
      <EndDate/>
      <RoleCode>Co-Principal Investigator</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>Andrew</FirstName>
      <LastName>Bennett</LastName>
      <EmailAddress>bennett@math.ksu.edu</EmailAddress>
      <StartDate>07/11/2002</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Kansas State University</Name>
      <CityName>MANHATTAN</CityName>
      <ZipCode>665061103</ZipCode>
      <PhoneNumber>7855326804</PhoneNumber>
      <StreetAddress>2 FAIRCHILD HALL</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Kansas</StateName>
      <StateCode>KS</StateCode>
    </Institution>
    <FoaInformation>
      <Code>0000099</Code>
      <Name>Other Applications NEC</Name>
    </FoaInformation>
    <ProgramElement>
      <Code>7431</Code>
      <Text>CCLI - ASA</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>7431</Code>
      <Text>CCLI - ASA</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>9150</Code>
      <Text>EXP PROG TO STIM COMP RES</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>9178</Code>
      <Text>UNDERGRADUATE EDUCATION</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>SMET</Code>
      <Text>SCIENCE, MATH, ENG &amp; TECH EDUCATION</Text>
    </ProgramReference>
  </Award>
</rootTag>
