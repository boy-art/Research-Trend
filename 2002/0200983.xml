<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>Synthesis and Acquisition of Communicative Gestures</AwardTitle>
    <AwardEffectiveDate>09/15/2002</AwardEffectiveDate>
    <AwardExpirationDate>08/31/2005</AwardExpirationDate>
    <AwardAmount>427000</AwardAmount>
    <AwardInstrument>
      <Value>Continuing grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05020000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Information &amp; Intelligent Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Tatiana D. Korelsky</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Procedural synthesis of natural and contextually appropriate gestures in embodied virtual human agents is challenging. Laban Movement Analysis (LMA) offers a descriptive system for human gesture qualities that fills the gap between pre-defined gesture playback systems and human animator intuition. A computational analog of LMA called EMOTE has been constructed whose parameters modify the performance qualities of arm gesture movements. EMOTE will be developed in several new ways:&lt;br/&gt;&lt;br/&gt;* Connect EMOTE with an agent model so that an agent's affect, personality, and communicative needs set appropriate EMOTE parameters for gesture performance.&lt;br/&gt;&lt;br/&gt;* Investigate motion analysis techniques for extracting EMOTE parameters from live dual or single camera views.&lt;br/&gt;&lt;br/&gt;* Experimentally validate the automated acquisition of EMOTE parameters by using professional LMA notators for ground truth.&lt;br/&gt;&lt;br/&gt;* Use the extracted parameters to create instances of parameterized actions which may be subsequently used for action, affect, and manner descriptions and, ultimately, for content-directed analysis of existing film or video material.&lt;br/&gt;&lt;br/&gt;This study will help set synthetic agent animation techniques on a sound empirical footing, provide evidence that computers can in fact observe important motion qualities, and lead to strong connections between internal agent state and external behavior qualities.</AbstractNarration>
    <MinAmdLetterDate>09/13/2002</MinAmdLetterDate>
    <MaxAmdLetterDate>04/14/2005</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>0200983</AwardID>
    <Investigator>
      <FirstName>Dimitris</FirstName>
      <LastName>Metaxas</LastName>
      <EmailAddress>dnm@cs.rutgers.edu</EmailAddress>
      <StartDate>09/13/2002</StartDate>
      <EndDate/>
      <RoleCode>Co-Principal Investigator</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>Norman</FirstName>
      <LastName>Badler</LastName>
      <EmailAddress>badler@central.cis.upenn.edu</EmailAddress>
      <StartDate>09/13/2002</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of Pennsylvania</Name>
      <CityName>Philadelphia</CityName>
      <ZipCode>191046205</ZipCode>
      <PhoneNumber>2158987293</PhoneNumber>
      <StreetAddress>Research Services</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Pennsylvania</StateName>
      <StateCode>PA</StateCode>
    </Institution>
    <FoaInformation>
      <Code>0104000</Code>
      <Name>Information Systems</Name>
    </FoaInformation>
    <FoaInformation>
      <Code>0116000</Code>
      <Name>Human Subjects</Name>
    </FoaInformation>
  </Award>
</rootTag>
