<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>New Directions in Dimension Reduction</AwardTitle>
    <AwardEffectiveDate>07/01/2002</AwardEffectiveDate>
    <AwardExpirationDate>01/31/2006</AwardExpirationDate>
    <AwardAmount>178543</AwardAmount>
    <AwardInstrument>
      <Value>Continuing grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>03040200</Code>
      <Directorate>
        <LongName>Direct For Mathematical &amp; Physical Scien</LongName>
      </Directorate>
      <Division>
        <LongName>Division Of Mathematical Sciences</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>grace yang</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Abstract&lt;br/&gt;&lt;br/&gt;DMS-0204662&lt;br/&gt;PI: Bing Li&lt;br/&gt;&lt;br/&gt;This research will develop methods in dimension reduction, which aim at increased accuracy and a wider spectrum of applications. Specifically, the work will proceed in three main directions. (1) The classical formulation makes the conditional density in regression the target for dimension reduction. This does not take into consideration that in many applications the primary interest centers in the conditional mean. Moreover, the classical formulation requires homoskedasticity among predictors, which can be too restrictive for some problems. To address these issues the investigator proposes to reformulate the problem as reducing the dimensions of the predictors as they appear in the conditional mean. This will allow further dimension reduction, it will improve accuracy and remove the requirement for homoskedasticity. (2) Within the classical formulation one cannot handle categorical predictors, which occur frequently in practice. This research will broaden the proposed formulation so that it can handle such cases. (3) It is then possible and natural to combine these two new elements to further develop a more focused, and less restricted dimension reduction method for conditional means for regressions involving categorical predictors. &lt;br/&gt;&lt;br/&gt;The methods of dimension reduction were introduced originally to provide a comprehensive graphical tool for exploratory data analysis. Recently, active developments are under way due to the rapid growth of computing power; this has dramatically increased the scope and dimensions of the collected data sets. Besides its important role as a graphic method, dimension reduction is particularly useful in problems where interest lies in identifying connections among the variables, such as classification and clustering. It is also useful when the dimension of a data point exceeds the total number of data points, which is typically the case for many scientific data sets, such as gene expression data. But the available dimension reduction methods have several limitations, such as assuming homogeneity between predictors and not be able to handle categorical predictors. This research will tackle these limitations of the current methodology.</AbstractNarration>
    <MinAmdLetterDate>06/28/2002</MinAmdLetterDate>
    <MaxAmdLetterDate>04/05/2004</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>0204662</AwardID>
    <Investigator>
      <FirstName>Bing</FirstName>
      <LastName>Li</LastName>
      <EmailAddress>bing@stat.psu.edu</EmailAddress>
      <StartDate>06/28/2002</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Pennsylvania State Univ University Park</Name>
      <CityName>UNIVERSITY PARK</CityName>
      <ZipCode>168027000</ZipCode>
      <PhoneNumber>8148651372</PhoneNumber>
      <StreetAddress>110 Technology Center Building</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Pennsylvania</StateName>
      <StateCode>PA</StateCode>
    </Institution>
    <FoaInformation>
      <Code>0000099</Code>
      <Name>Other Applications NEC</Name>
    </FoaInformation>
  </Award>
</rootTag>
