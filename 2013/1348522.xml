<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>Verb Learning and The Early Development of Sentence Comprehension: Experimental and Computational Studies</AwardTitle>
    <AwardEffectiveDate>09/01/2014</AwardEffectiveDate>
    <AwardExpirationDate>02/28/2018</AwardExpirationDate>
    <AwardAmount>190210</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>04040000</Code>
      <Directorate>
        <LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
      </Directorate>
      <Division>
        <LongName>Division Of Behavioral and Cognitive Sci</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>William J. Badecker</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Understanding how children learn language--how they gather data from language experience and use it to uncover linguistic structure--is a key challenge for cognitive science, in part because native mastery of a language is one of the foundations of both formal and informal education. Infant language learners encounter sentences paired with world situations; at the start, these sentences are made up of unknown words, combined by the rules of an unknown grammar. Based on such data, toddlers begin to understand sentences early in the second year of life, and ultimately build a lexicon and grammar that support nearly unlimited generalization to new sentences. Accounts of how children begin to understand sentences necessarily begin with the non-linguistic world. The infant, not yet knowing the words or the grammar, must figure out what words and sentences mean in large part by observing the world situations in which they occur. But aspects of the meanings of verbs challenge the assumption that learners can straightforwardly recover verb (and thus sentence) meanings from situations. This problem inspired the syntactic bootstrapping theory, which proposes that children use their growing knowledge of syntax itself to learn verbs and interpret sentences. &lt;br/&gt;&lt;br/&gt;This research is will provide important insight into normal language acquisition, but it may, in the future, contribute also to the diagnosis and treatment of developmental language disorders. In this project, Dr. Fisher and Dr. Roth explore how syntactic bootstrapping works, and how it begins, extending the structure-mapping account of the origins of syntactic bootstrapping. On this account, infants approach language armed with an innate bias toward one-to-one mapping between nouns in sentences and participant-roles in events. Given this bias, children find the number of nouns in a sentence inherently meaningful: For example, as soon as children can identify some nouns, they can assign different interpretations to transitive and intransitive verbs, essentially by counting the nouns. A corollary of this account is that children identify words as verbs by learning their syntactic combinatorial properties. &lt;br/&gt;&lt;br/&gt;This project asks how syntactic bootstrapping scales up to the complexity of verbs' predicate-argument structures and the ambiguity of sentences. The project addresses two linked proposals, by combining verb-learning experiments with children and experiments with a computational model based on systems for Semantic Role Labeling (SRL). The first proposal is that distributional learning creates detailed syntactic-semantic combinatorial knowledge about verbs. This knowledge plays two roles: (a) it permits syntactic bootstrapping, as children use verbs' combinatorial behavior to identify them as verbs, and to compute their semantic structure; and (b) it supports online sentence processing, by reducing ambiguity and improving children's sentence representations (this is known as 'verb bias'). The second proposal is that an expectation of discourse continuity facilitates verb learning by letting learners gather evidence for verb argument-structure across nearby sentences. Combinatorial learning about verbs guides this process, by cuing children to seek referents for missing arguments in the discourse context.</AbstractNarration>
    <MinAmdLetterDate>08/14/2014</MinAmdLetterDate>
    <MaxAmdLetterDate>08/14/2014</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1348522</AwardID>
    <Investigator>
      <FirstName>Cynthia</FirstName>
      <LastName>Fisher</LastName>
      <EmailAddress>clfishe@illinois.edu</EmailAddress>
      <StartDate>08/14/2014</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>Dan</FirstName>
      <LastName>Roth</LastName>
      <EmailAddress>danr@illinois.edu</EmailAddress>
      <StartDate>08/14/2014</StartDate>
      <EndDate/>
      <RoleCode>Co-Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of Illinois at Urbana-Champaign</Name>
      <CityName>CHAMPAIGN</CityName>
      <ZipCode>618207473</ZipCode>
      <PhoneNumber>2173332187</PhoneNumber>
      <StreetAddress>SUITE A</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Illinois</StateName>
      <StateCode>IL</StateCode>
    </Institution>
    <ProgramElement>
      <Code>1698</Code>
      <Text>DS - Developmental Sciences</Text>
    </ProgramElement>
    <ProgramElement>
      <Code>1311</Code>
      <Text>LINGUISTICS</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>1311</Code>
      <Text>LINGUISTICS</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>9178</Code>
      <Text>UNDERGRADUATE EDUCATION</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>9179</Code>
      <Text>GRADUATE INVOLVEMENT</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>1698</Code>
      <Text>DEVELOP&amp; LEARNING SCIENCES/CRI</Text>
    </ProgramReference>
  </Award>
</rootTag>
