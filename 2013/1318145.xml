<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>RI: Small: Dynamic Invariants for Video Scenes Understanding</AwardTitle>
    <AwardEffectiveDate>09/01/2013</AwardEffectiveDate>
    <AwardExpirationDate>08/31/2017</AwardExpirationDate>
    <AwardAmount>454999</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05020000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Information &amp; Intelligent Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Jie Yang</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>This project aims to use a combination of elements from dynamic vision, dynamical systems theory, optimization and semi-algebraic geometry to develop a computationally tractable, scalable framework for automatic dynamic scene understanding from multiple, potentially incomplete and corrupted data streams. The long-term vision is to lay the foundations for synthesizing provably robust vision systems, capable of sustained successful operation in complex dynamic scenarios.&lt;br/&gt;&lt;br/&gt;The core of the project is a unified vision, centered on the use of dynamical invariants as information encapsulators, and emphasizing robustness and computational complexity issues. In this approach, the observed data is treated as the output of an underlying model, typically a difference inclusion, which has associated certain quantities (for example order, embedding manifold, subspace spanned by its trajectories) that are invariant to coordinate transformations, initial conditions, viewpoint changes, synchronization, etc. These invariants compactly capture spatio-temporal information from video data and lead to robust, computationally efficient algorithms for automatic video scene understanding. For instance, in this context video data can be efficiently segmented by detecting changes in these dynamic invariants or clustered according to a suitable defined distance. An application domain directly impacted by this research is aware environments for public space safety, where the co-PIs have been provided access to real data and given a venue for real time testing of the algorithms.</AbstractNarration>
    <MinAmdLetterDate>08/21/2013</MinAmdLetterDate>
    <MaxAmdLetterDate>08/21/2013</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1318145</AwardID>
    <Investigator>
      <FirstName>Octavia</FirstName>
      <LastName>Camps</LastName>
      <EmailAddress>camps@ece.neu.edu</EmailAddress>
      <StartDate>08/21/2013</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>Mario</FirstName>
      <LastName>Sznaier</LastName>
      <EmailAddress>msznaier@coe.neu.edu</EmailAddress>
      <StartDate>08/21/2013</StartDate>
      <EndDate/>
      <RoleCode>Co-Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Northeastern University</Name>
      <CityName>BOSTON</CityName>
      <ZipCode>021155005</ZipCode>
      <PhoneNumber>6173732508</PhoneNumber>
      <StreetAddress>360 HUNTINGTON AVE</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Massachusetts</StateName>
      <StateCode>MA</StateCode>
    </Institution>
    <ProgramElement>
      <Code>7495</Code>
      <Text>ROBUST INTELLIGENCE</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>7495</Code>
      <Text>ROBUST INTELLIGENCE</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>7923</Code>
      <Text>SMALL PROJECT</Text>
    </ProgramReference>
  </Award>
</rootTag>
