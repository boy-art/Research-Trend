<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>HCC: Small: Effective Augmented Reality Depth Representation Methods and Accuracy Evaluations Inspired by Medical Applications</AwardTitle>
    <AwardEffectiveDate>09/15/2013</AwardEffectiveDate>
    <AwardExpirationDate>08/31/2017</AwardExpirationDate>
    <AwardAmount>498233</AwardAmount>
    <AwardInstrument>
      <Value>Continuing grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05020000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Information &amp; Intelligent Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Ephraim P. Glinert</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Augmented reality (AR) systems, which are computer systems that enhance the viewing of physical objects in the world with computer data, are currently held back from widespread use for many real-world applications because of the unsolved human-computer interaction problem of how to accurately convey to a person how far away from that person a computer-generated object is intended to appear. People using AR systems routinely misjudge the depth of AR-presented objects. This is especially true for AR objects that should appear to be located behind opaque occluding surfaces; in this case AR should produce an "x-ray vision" perceptual experience that makes the occluding surface appear to become transparent. The perceptual phenomena that underlie this problem relate to (a) conflicting depth cues that naturally arise with AR technology, especially incorrect occlusion cues in optical "x-ray vision" AR, (b) conflicting findings from techniques that have been developed to measure depth perception within reaching distance, and (c) the role of practice and feedback in training to correct these depth misjudgments.&lt;br/&gt;&lt;br/&gt;This project will evaluate AR depth representation methods and explain the underlying phenomena, with an emphasis on medical AR tasks and applications. The project will develop and evaluate a head-worn haploscope to allow researchers to study the depth cues of accommodation and vergence AR. The project will create and evaluate vergence-based methods for rendering AR information in depth; that is, techniques in which people can control the appearance of computer data inside of a physical object by rotating their eyes as is needed to look at near and far objects. The researchers on this project will collaborate with experts on the use of AR for medical applications to develop new vergence-based techniques for AR "x-ray vision" in the medical domain. &lt;br/&gt;&lt;br/&gt;Broader Impacts: Vergence-based AR applications have the potential to improve health outcomes for a broad array of medical procedures, and also to improve human capabilities in task domains such as manufacturing and equipment maintenance. This project will hasten the timeframe for successfully developing and deploying such applications. Students working on this project will be trained in an interdisciplinary context that rigorously studies the intimate interplay between computer graphics and human perception. The interdisciplinary and human-centered aspects of the project will help to recruit students who might otherwise be less likely to gravitate to computer science.</AbstractNarration>
    <MinAmdLetterDate>09/03/2013</MinAmdLetterDate>
    <MaxAmdLetterDate>07/14/2014</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1320909</AwardID>
    <Investigator>
      <FirstName>J. Edward</FirstName>
      <LastName>Swan II</LastName>
      <EmailAddress>swan@cse.msstate.edu</EmailAddress>
      <StartDate>09/03/2013</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Mississippi State University</Name>
      <CityName>MISSISSIPPI STATE</CityName>
      <ZipCode>397629662</ZipCode>
      <PhoneNumber>6623257404</PhoneNumber>
      <StreetAddress>PO Box 6156</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Mississippi</StateName>
      <StateCode>MS</StateCode>
    </Institution>
    <ProgramElement>
      <Code>7367</Code>
      <Text>Cyber-Human Systems (CHS)</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>7367</Code>
      <Text>Cyber-Human Systems</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>7923</Code>
      <Text>SMALL PROJECT</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>9150</Code>
      <Text>EXP PROG TO STIM COMP RES</Text>
    </ProgramReference>
  </Award>
</rootTag>
