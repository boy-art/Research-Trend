<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>EAGER: A Local-Global Approach Towards Omnipresent Vision</AwardTitle>
    <AwardEffectiveDate>09/15/2013</AwardEffectiveDate>
    <AwardExpirationDate>08/31/2016</AwardExpirationDate>
    <AwardAmount>184416</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05020000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Information &amp; Intelligent Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Jie Yang</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>This project constructs an Omnipresent Vision system - a computational system that allows us to navigate, share, enhance, and understand the visual data captured by a slew of fixed and moving cameras. The society is flooded with various cameras. Almost every cell phone has a video camera and wearable cameras are starting to permeate our lives. These local cameras capture visual experiences from personal perspectives. Static cameras at various outdoor and indoor locations are also constantly capturing videos. These fixed-view cameras offer global, persistent looks into our daily lives. The key idea of this project is to fully leverage the combination of these local and global cameras to enable new visual experiences and facilitate the understanding of the scene and the people within. This is achieved with novel algorithms and computational tools that bring together the local and global views into an integrated platform, model the dynamic scene by joining those two sets of perspectives, and recognize the actions and events in them. &lt;br/&gt;&lt;br/&gt;The research, at a personal level, enables the spatio-temporal and contextual expansion of the person's view, and at a scene level, it enables the interpretation of the scene at various scales of spatial and temporal resolutions. It also provides new means to understand people and scenes. For instance, it facilitates the understanding of people who cannot communicate their intentions. The research activities also furnish graduate and undergraduate students educational opportunities to take part in spawning this new area of research.</AbstractNarration>
    <MinAmdLetterDate>09/04/2013</MinAmdLetterDate>
    <MaxAmdLetterDate>09/04/2013</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1353235</AwardID>
    <Investigator>
      <FirstName>Ko</FirstName>
      <LastName>Nishino</LastName>
      <EmailAddress>kon@drexel.edu</EmailAddress>
      <StartDate>09/04/2013</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Drexel University</Name>
      <CityName>Philadelphia</CityName>
      <ZipCode>191021119</ZipCode>
      <PhoneNumber>2158955849</PhoneNumber>
      <StreetAddress>1505 Race St, 8th Floor</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Pennsylvania</StateName>
      <StateCode>PA</StateCode>
    </Institution>
    <ProgramElement>
      <Code>7495</Code>
      <Text>ROBUST INTELLIGENCE</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>7495</Code>
      <Text>ROBUST INTELLIGENCE</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>7916</Code>
      <Text>EAGER</Text>
    </ProgramReference>
  </Award>
</rootTag>
