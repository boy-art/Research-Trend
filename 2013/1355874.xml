<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>I-Corps: Social Gaze for Software Agents and Robots</AwardTitle>
    <AwardEffectiveDate>02/01/2014</AwardEffectiveDate>
    <AwardExpirationDate>07/31/2014</AwardExpirationDate>
    <AwardAmount>50000</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>07070000</Code>
      <Directorate>
        <LongName>Directorate For Engineering</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Industrial Innovation &amp; Partnersh</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Rathindra DasGupta</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>This proposal further develops a software package that autonomously generates head and eye movements, in a virtual assistant or social robot synchronized with real-time speech for "human-like" conversation. Existing solutions use preprogrammed head and eye movements for conversation, as current technology cannot synchronize head and eye gaze for real-time speech. The proposed technology can be used in interactive open-ended conversations and can adapt to gender and culture of the conversation partner. This project presents three contributions to human-computer and human-robot interaction. First, autonomous generation of head and eye gaze in a virtual assistant or social robot synchronized with real-time speech for open-ended interactive conversations. Second, the front end of the social agent responsible for gesture generation is completely independent of the back end knowledge base; hence deployments of virtual assistant or social robot solutions are easier, cheaper, and faster. Third, the technology enables generation of social gaze sensitive to gender and culture. &lt;br/&gt;&lt;br/&gt;The broader impact of the project include the validated benefits of the technology for end users, such as increased social acceptance, increased positive feelings, increased engagement, improved understandability, and superior likeability. Stemming from encouraging initial discussions with end users the proposed technology may be transformative in a large number of markets like video games, online marketing, web customer service, telepresence, telemedicine, entertainment, eldercare, and healthcare.&lt;br/&gt;A successful deployment of the technology may result in substantial cost savings to organizations that deploy virtual assistant or social robot solutions, and increased revenues for the vendors of these solutions due to accelerated consumer adoption.</AbstractNarration>
    <MinAmdLetterDate>01/22/2014</MinAmdLetterDate>
    <MaxAmdLetterDate>04/10/2014</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1355874</AwardID>
    <Investigator>
      <FirstName>Robin</FirstName>
      <LastName>Murphy</LastName>
      <EmailAddress>murphy@cse.tamu.edu</EmailAddress>
      <StartDate>01/22/2014</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Texas A&amp;M Engineering Experiment Station</Name>
      <CityName>College Station</CityName>
      <ZipCode>778454645</ZipCode>
      <PhoneNumber>9798477635</PhoneNumber>
      <StreetAddress>TEES State Headquarters Bldg.</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Texas</StateName>
      <StateCode>TX</StateCode>
    </Institution>
    <ProgramElement>
      <Code>8023</Code>
      <Text>I-Corps</Text>
    </ProgramElement>
  </Award>
</rootTag>
