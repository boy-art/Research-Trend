<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>NSF Postdoctoral Fellowship in Biology FY 2013</AwardTitle>
    <AwardEffectiveDate>06/01/2013</AwardEffectiveDate>
    <AwardExpirationDate>05/31/2015</AwardExpirationDate>
    <AwardAmount>138000</AwardAmount>
    <AwardInstrument>
      <Value>Fellowship</Value>
    </AwardInstrument>
    <Organization>
      <Code>08080000</Code>
      <Directorate>
        <LongName>Direct For Biological Sciences</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Biological Infrastructure</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Michael Vanni</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Neural mechanisms of mobile prey detection during locomotion&lt;br/&gt;&lt;br/&gt;The visual world of animals is always in motion. A video camera mounted directly onto the eyeball would record a blur of perpetual movement. Visual motion can signal the presence of behaviorally important objects such as prey or predators, yet each time an animal shifts its gaze or engages in locomotion, the visual surround also moves. How does the brain distinguish between visual motion caused by movement of the eyes, head or body, versus visual motion caused by mobile objects in the environment? To tackle this question, this fellowship will support the development of innovative, virtual reality methods that will be combined with genetic techniques to record the activity of specific circuit elements in the brain of larval zebrafish while they attempt to visually track and capture "virtual" prey items. In zebrafish and many other vertebrates, the ability to capture prey is reliant on a midbrain structure called the optic tectum; however, very little is known about identity or function of neural circuits in the tectum or elsewhere in the brain that function to detect and direct attention towards mobile prey. Although current neural recording techniques require that fish be immobilized, a virtual reality system overcomes this limitation by simulating the motion of the visual world that fish would experience while freely swimming. Critically, a virtual reality system will make it possible to experimentally decouple changes in the sensory surround from motor actions, allowing for a precise dissection of feedback mechanisms between sensory and motor processing in the nervous system.&lt;br/&gt;&lt;br/&gt;Training goals include learning to implement real-time, closed-loop controllers for visual displays, and learning to use genetic methods for identifying and imaging neurons in zebrafish. This fellowship will also support the development of a human eye-tracking, virtual reality system, to be used in the classroom or in a public venue, such as a museum. This eye-tracking system will allow students or the public to interactively investigate relationships between their movement and their perception of motion.</AbstractNarration>
    <MinAmdLetterDate>05/14/2013</MinAmdLetterDate>
    <MaxAmdLetterDate>05/14/2013</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1306695</AwardID>
    <Investigator>
      <FirstName>Matthew</FirstName>
      <LastName>Green</LastName>
      <EmailAddress/>
      <StartDate>05/14/2013</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Green Matthew H</Name>
      <CityName>Evanston</CityName>
      <ZipCode>602083111</ZipCode>
      <PhoneNumber/>
      <StreetAddress/>
      <CountryName>United States</CountryName>
      <StateName>Illinois</StateName>
      <StateCode>IL</StateCode>
    </Institution>
    <ProgramElement>
      <Code>8054</Code>
      <Text>Inters Biol and Math and Phys</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>7137</Code>
      <Text>POSTDOCTORAL FELLOWSHIPS</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>7174</Code>
      <Text>POSTDOC FELLOW IN SCI, MATH EN</Text>
    </ProgramReference>
  </Award>
</rootTag>
