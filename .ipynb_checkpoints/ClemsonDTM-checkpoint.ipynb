{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as et \n",
    "from gensim import corpora\n",
    "from pprint import pprint \n",
    "from collections import defaultdict\n",
    "import glob \n",
    "\n",
    "#Dictionary for all award ID's and Abstracts \n",
    "global awards\n",
    "awards=dict()\n",
    "\n",
    "#Array storage for Award IDs and Abstracts \n",
    "awardabs_ar=[\"Null\"]\n",
    "aID_ar=[\"Null\"]\n",
    "\n",
    "#Counts The number of items found with an Abstract vs without \n",
    "without = 0\n",
    "T_with = 0 \n",
    "grandtotal = 0\n",
    "\n",
    "#Used as a condition for later statement \n",
    "x = 0\n",
    "\n",
    "#Function Declaration \n",
    "def addIDandAbs(ID,abstract):\n",
    "    for i in awards:\n",
    "        #Checks for duplicates \n",
    "        if i == ID:\n",
    "            print(\"Error\")\n",
    "            return\n",
    "    #Store ID and Abstract\n",
    "    awards[ID] = abstract\n",
    "    awardabs.append(abstract)\n",
    "    aID_ar.append(ID)\n",
    "    \n",
    "for items in glob.glob(\"201*/*.xml\"): #Iterate through all xml files in the directory/file name given\n",
    "    #Open files\n",
    "    item = open(items)\n",
    "    #Store Data\n",
    "    str_data = item.read()\n",
    "    #Convert data to text \n",
    "    data = et.fromstring(str_data)\n",
    "    #store the current name of the institution \n",
    "    clemson = data.find(\"Award\").find(\"Institution\").find(\"Name\").text\n",
    "    #Check if the name matches Clemson University \n",
    "    if clemson==\"Clemson University\" :\n",
    "        #Add award ID and Abstract to the dictionary awards\n",
    "        #addIDandAbs(data.find(\"Award\").find(\"AwardID\").text,data.find(\"Award\").find(\"AbstractNarration\").text)\n",
    "        ID = data.find(\"Award\").find(\"AwardID\").text\n",
    "        abstract = data.find(\"Award\").find(\"AbstractNarration\").text\n",
    "        awards[ID]=abstract\n",
    "        #Keep count of the number of items found \n",
    "        T_with = T_with + 1\n",
    "    else:\n",
    "        #Optional Keep count of the number of items not found \n",
    "        without = without + 1\n",
    "    #Optional Total Articles:\n",
    "    grandtotal = grandtotal + 1\n",
    "#Store Data into arrays from the library \n",
    "for i,v in awards.items():\n",
    "    #Stores the first abstract and key into the first part of the array so append will see that the list is not empty.\n",
    "    if x == 0:\n",
    "        awardabs_ar[0]=v\n",
    "        aID_ar[0]=i\n",
    "    else:\n",
    "        awardabs_ar.append(v)\n",
    "        aID_ar.append(i)\n",
    "    x = x + 1\n",
    "#Optional print code for data in first part of array\n",
    "#for l in range(T_with):\n",
    "    #print(\"Award ID:\\n\"+aID_ar[l],\"\\n\\nAward Abstract:\\n\"+awardabs_ar[l]+\"\\n\")\n",
    "file=open(\"cu_tigers.txt\",\"w\")    \n",
    "\n",
    "awardabs_ar = map(lambda x: x+\"\\n\", awardabs_ar)\n",
    "file.writelines(awardabs_ar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used files generated from first tutorial\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora,models,similarities\n",
    "from pprint import pprint \n",
    "from collections import defaultdict\n",
    "import os\n",
    "\n",
    "file = open('cu_tigers.txt', 'r')\n",
    "dictionary = file.readlines()\n",
    "\n",
    "#removed word list    \n",
    "r_words = 'side up end was all than ever despite often large has have been there know provide near two well some offer much higher low each within about such one uses over being approach its but if can which used or no other may who details it an few many thus must their more also these find at on via with would on find from due for a of the and to in not them is that will be as they will how understanding lay into by both are aspects give every new use this'\n",
    "#remove common words and tokenize\n",
    "stoplist = set(r_words.split())\n",
    "texts = [[word for word in document.lower().split() if word not in stoplist]\n",
    "          for document in dictionary]\n",
    "\n",
    "# remove words that appear only once\n",
    "frequency = defaultdict(int)\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "\n",
    "texts = [[token for token in text if frequency[token] > 1]\n",
    "          for text in texts]\n",
    "\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "dictionary.save('cutigers.dict')\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "corpora.MmCorpus.serialize('cutigers.mm', corpus)\n",
    "\n",
    "\n",
    "if(os.path.exists(\"cutigers.dict\")):\n",
    "    dictionary = corpora.Dictionary.load('cutigers.dict')\n",
    "    corpus = corpora.MmCorpus('cutigers.mm')\n",
    "    print(\"Used files generated from first tutorial\")\n",
    "else:\n",
    "    print(\"Please run first tutorial to generate data set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Anaconda 2.5.0 (Python 3)",
   "language": "python",
   "name": "anaconda_2.5.0_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
