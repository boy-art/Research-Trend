{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-25491d156553>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0mI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mID\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0mD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m     \u001b[0mtable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mI\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlda5\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0mb\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jallen2/.local/lib/python3.5/site-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, bow, eps)\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m         \"\"\"\n\u001b[0;32m--> 987\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_document_topics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'state'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dispatcher'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jallen2/.local/lib/python3.5/site-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36mget_document_topics\u001b[0;34m(self, bow, minimum_probability, minimum_phi_value, per_word_topics)\u001b[0m\n\u001b[1;32m    926\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 928\u001b[0;31m         \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollect_sstats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    929\u001b[0m         \u001b[0mtopic_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# normalize distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jallen2/.local/lib/python3.5/site-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36minference\u001b[0;34m(self, chunk, collect_sstats)\u001b[0m\n\u001b[1;32m    442\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteger_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m                 \u001b[0;31m# make sure the term IDs are ints, otherwise numpy will get upset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m                 \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m                 \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jallen2/.local/lib/python3.5/site-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    442\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteger_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m                 \u001b[0;31m# make sure the term IDs are ints, otherwise numpy will get upset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m                 \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m                 \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models, similarities\n",
    "from collections import defaultdict\n",
    "import gensim\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "#dictionary for probability table\n",
    "table = {}\n",
    "\n",
    "#All Ids file\n",
    "file01 = open('cu_IDs.txt', 'r')\n",
    "ID = file01.readlines()\n",
    "\n",
    "#Doctorates and Divisions file\n",
    "file02 = open('cu_doc_div.txt', 'r')\n",
    "dict_div = file02.readlines()\n",
    "    \n",
    "\n",
    "#20% arrays Probability \n",
    "ar1 = [\"NULL\"]\n",
    "ar2 = [\"NULL\"]\n",
    "ar3 = [\"NULL\"]\n",
    "ar4 = [\"NULL\"]\n",
    "ar5 = [\"NULL\"]\n",
    "\n",
    "#20% arrays convertion to vectors \n",
    "doc001 = [\"NULL\"]\n",
    "doc002 = [\"NULL\"]\n",
    "doc003 = [\"NULL\"]\n",
    "doc004 = [\"NULL\"]\n",
    "doc005 = [\"NULL\"]\n",
    "\n",
    "\n",
    "#holds all arrays\n",
    "box = []\n",
    "\n",
    "#increment variable for 20% arrays\n",
    "a = 0\n",
    "b = 0\n",
    "c = 0\n",
    "d = 0\n",
    "e = 0 \n",
    "f = 0\n",
    "g = 0\n",
    "num = 0 \n",
    "num1 = 0\n",
    "\n",
    "\n",
    "# 20% abstract files\n",
    "file1 = open('cu_test_doc1.txt', 'r')\n",
    "doc1 = file1.readlines()\n",
    "file2 = open('cu_test_doc2.txt', 'r')\n",
    "doc2 = file2.readlines()\n",
    "file3 = open('cu_test_doc3.txt', 'r')\n",
    "doc3 = file3.readlines()\n",
    "file4 = open('cu_test_doc4.txt', 'r')\n",
    "doc4 = file4.readlines()\n",
    "file5 = open('cu_test_doc5.txt', 'rb')\n",
    "doc5 = file5.readlines()\n",
    "\n",
    "\n",
    "#Load 80% Dictionary \n",
    "dictionary1 = corpora.Dictionary.load('/tmp/cu_dict1.dict')\n",
    "dictionary2 = corpora.Dictionary.load('/tmp/cu_dict2.dict')\n",
    "dictionary3 = corpora.Dictionary.load('/tmp/cu_dict3.dict')\n",
    "dictionary4 = corpora.Dictionary.load('/tmp/cu_dict4.dict')\n",
    "dictionary5 = corpora.Dictionary.load('/tmp/cu_dict5.dict')\n",
    "\n",
    "#Load 80% Corpus \n",
    "corpus1 = corpora.MmCorpus('/tmp/cu_corpus1.mm')\n",
    "corpus2 = corpora.MmCorpus('/tmp/cu_corpus2.mm')\n",
    "corpus3 = corpora.MmCorpus('/tmp/cu_corpus3.mm')\n",
    "corpus4 = corpora.MmCorpus('/tmp/cu_corpus4.mm')\n",
    "corpus5 = corpora.MmCorpus('/tmp/cu_corpus5.mm')\n",
    "\n",
    "#Load 80% lda model \n",
    "lda1 = models.LdaModel.load('/tmp/CuModel_1.lda')\n",
    "lda2 = models.LdaModel.load('/tmp/CuModel_2.lda')\n",
    "lda3 = models.LdaModel.load('/tmp/CuModel_3.lda')\n",
    "lda4 = models.LdaModel.load('/tmp/CuModel_4.lda')\n",
    "lda5 = models.LdaModel.load('/tmp/CuModel_5.lda')\n",
    "\n",
    "\n",
    "for x in range(20):\n",
    "    if num == 0: \n",
    "        doc001[0] = dictionary1.doc2bow(doc1[num].lower().split())\n",
    "        doc002[0] = dictionary2.doc2bow(doc2[num].lower().split())\n",
    "        doc003[0] = dictionary3.doc2bow(doc3[num].lower().split())\n",
    "        doc004[0] = dictionary4.doc2bow(doc4[num].lower().split())\n",
    "        num += 1 \n",
    "    else:\n",
    "        holder1 = dictionary1.doc2bow(doc1[num].lower().split())\n",
    "        doc001.append(holder1)\n",
    "        holder2 = dictionary2.doc2bow(doc2[num].lower().split())\n",
    "        doc002.append(holder2)\n",
    "        holder3 = dictionary3.doc2bow(doc3[num].lower().split())\n",
    "        doc003.append(holder3)\n",
    "        holder4 = dictionary4.doc2bow(doc4[num].lower().split())\n",
    "        doc004.append(holder4)\n",
    "        num += 1 \n",
    "for y in range(17):\n",
    "    if num1 == 1: \n",
    "        doc005[0] = dictionary5.doc2bow(doc5[num1].lower().split())\n",
    "        num1 += 1 \n",
    "    else: \n",
    "        holder5 = dictionary5.doc2bow(doc5[num1].lower().split())\n",
    "        doc005.append(holder5)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "box = doc001 + doc002 + doc003 + doc004 + doc005\n",
    "\n",
    "\n",
    "for n in range(20):\n",
    "    I = ID[b] #0-19 --> 20 \n",
    "    D = box[b] #0-19 --> 20  \n",
    "    table[I] = lda1[D]\n",
    "    b += 1\n",
    "for n in range(20):\n",
    "    I = ID[b]\n",
    "    D = box[b]\n",
    "    table[I] = lda2[D]\n",
    "    b += 1\n",
    "for n in range(20):\n",
    "    I = ID[b]\n",
    "    D = box[b]\n",
    "    table[I] = lda3[D]\n",
    "    b += 1\n",
    "for n in range(20):\n",
    "    I = ID[b]\n",
    "    D = box[b]\n",
    "    table[I] = lda4[D]\n",
    "    b += 1 \n",
    "for n in range(17):\n",
    "    I = ID[b]\n",
    "    D = box[b]\n",
    "    table[I] = lda5[D]\n",
    "    b += 1\n",
    "    \n",
    "\n",
    "print(table, \"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "dictionary = corpora.Dictionary.load('/tmp/cu_dict.dict')\n",
    "corpus = corpora.MmCorpus('/tmp/cu_corpus.mm')\n",
    "lda = models.LdaModel.load('/tmp/CuModel.lda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim import corpora, models, similarities\n",
    "from collections import defaultdict\n",
    "import gensim\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "\n",
    "#Open the xml file\n",
    "test_doc = open('2016/1600011.xml','r')\n",
    "\n",
    "#Store data from xml file \n",
    "xml = test_doc.read()\n",
    "\n",
    "#Convert data to iterable text  \n",
    "soup = BeautifulSoup(xml,'xml')\n",
    "    \n",
    "#find the abstract in the xml file and filter out non-word elements\n",
    "words = soup.AbstractNarration.string.replace('<br/>','').replace(',','').replace('.','').replace('\\n','')\n",
    "\n",
    "#concatinate the dictorate to its division and add a tab between them \n",
    "dic = soup.Directorate.LongName.string  \n",
    "div = soup.Division.LongName.string\n",
    "doc_div1 = dic + '\\t' + div\n",
    "\n",
    "\n",
    "#All abstracts file\n",
    "file = open('cu_tigers.txt','r') \n",
    "doc = file.readlines()\n",
    "\n",
    "#All Ids file\n",
    "file2 = open('cu_IDs.txt', 'r')\n",
    "doc2 = file2.readlines()\n",
    "\n",
    "#Doctorates and Divisions file\n",
    "file3 = open('cu_doc_div.txt', 'r')\n",
    "doc3 = file3.readlines()\n",
    "\n",
    "\n",
    "#load dictionary\n",
    "dictionary = corpora.Dictionary.load('/tmp/cu_dict.dict')\n",
    "\n",
    "#load corpus\n",
    "corpus = corpora.MmCorpus('/tmp/cu_corpus.mm') # comes from the first tutorial, \"From strings to vectors\"\n",
    "#Load Model\n",
    "\n",
    "topic_prob = [\"NULL\"]\n",
    "x = 0\n",
    "number = 1\n",
    "\n",
    "lda = models.LdaModel.load('/tmp/CuModel.lda')\n",
    "\n",
    "\n",
    "for word in lda.print_topics(25):\n",
    "    if x == 0:\n",
    "        topic_prob[0]=word\n",
    "        x = x + 1\n",
    "    else:\n",
    "        topic_prob.append(words)\n",
    "\n",
    "for t in topic_prob:\n",
    "    #print(\"Topic\",number,\":\",t,\"\\n\")\n",
    "    number = number + 1\n",
    "    \n",
    "#convert new document to vector tuples \n",
    "document = dictionary.doc2bow(words.lower().split())\n",
    "vec_lda = lda[document]\n",
    "\n",
    "\n",
    "\n",
    "print(vec_lda)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "x = 0\n",
    "doc = ['f','e','r']\n",
    "\n",
    "for x in range(len(doc)*2):\n",
    "    print(x)\n",
    "    x = x + 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim import corpora, models, similarities \n",
    "from collections import defaultdict\n",
    "import gensim\n",
    "from bs4 import BeautifulSoup\n",
    "import glob \n",
    "\n",
    "#Doctorates and Divisions file\n",
    "file1 = open('cu_doc_div.txt', 'r')\n",
    "doc1 = file1.readlines()\n",
    "\n",
    "#Doctorates and Divisions file\n",
    "file2 = open('cu_doc_div.txt', 'r')\n",
    "doc2 = file2.readlines()\n",
    "\n",
    "compare = [\"NULL\"]\n",
    "for items in glob.glob(\"2016/*.xml\"):\n",
    "    doc = open(items)\n",
    "    xml = doc.read()\n",
    "    soup = BeautifulSoup(xml,'xml')\n",
    "    clemson = soup.Name.string\n",
    "    if clemson == \"Clemson University\":\n",
    "        doc_div = soup.Directorate.LongName.string + \"\\t\" + soup.Division.LongName.string\n",
    "        if x == 0:\n",
    "            compare[0] = doc_div:\n",
    "\n",
    "for d1 in doc2:\n",
    "    print(d)\n",
    "for d2 in doc3:\n",
    "    print(d)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim import corpora, models, similarities \n",
    "from collections import defaultdict\n",
    "import gensim\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "file = open('cu_IDs.txt', 'r')\n",
    "doc = file.readlines()\n",
    "\n",
    "#All abstracts file\n",
    "file1 = open('cu_tigers.txt','r') \n",
    "doc1 = file1.readlines()\n",
    "\n",
    "#Doctorates and Divisions file\n",
    "file3 = open('cu_doc_div.txt', 'r')\n",
    "doc3 = file3.readlines()\n",
    "\n",
    "print(doc3[40])\n",
    "print(doc[40],'\\n')\n",
    "print(doc1[40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#****************************\n",
    "#Beautiful Soup Test Code \n",
    "\n",
    "#****************************\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "\n",
    "file = open('2002/0200012.xml','r')\n",
    "\n",
    "xml = file.read()\n",
    "\n",
    "soup = BeautifulSoup(xml,'xml')\n",
    "\n",
    "def remove(abstract):\n",
    "    abstract = soup.AbstractNarration.string.replace('<br/>','').replace(',','').replace('.','').replace('\\n','').replace('!','').replace('?','').replace('(1)','').replace('(2)','')\n",
    "    print(abstract)\n",
    "    return\n",
    "\n",
    "abstract = soup.AbstractNarration.string   \n",
    "remove(abstract)\n",
    "\n",
    "print(abstract)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Anaconda 2.5.0 (Python 3)",
   "language": "python",
   "name": "anaconda_2.5.0_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
