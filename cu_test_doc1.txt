A private land conservation tool conservation easements have become widely used in the United States over the past thirty years and their popularity may correspond to tax laws creating incentives for private land conservation in the public interest This research project will examine how shifting dynamics between conservation easement holders easement donors/sellers regional land use pressures and connections to conserved lands are affecting the spatial pattern public benefit and ecological integrity of conservation easements in different regions of the United States These dynamics will be examined at the fine scale; national and regional policy structures will be linked at the land parcel-level How public input during the conservation easement process affects the spatial use of easements as well as the neighborhood effects of easements on adjacent and county-level land costs will be analyzed Results from this research will be useful to land use planners both public and private who will benefit from a better understanding of the conveyance process and the environmental outcomes Students will be trained in database creation and assessment strengthening the nation's scientific workforce Employing multivariate spatial overlay and time-series analyses the relationship between political and legal factors and conservation easement propagation will be examined Regional spatial datasets will be combined with the results from county-level easement donor surveys and both fine and coarse filter ecological integrity approaches to assess whether conservation easements whose purpose is to maintain biological integrity have a higher likelihood of contributing to reserve networks in their spatial arrangement than do other conservation easements Whether this is more likely to occur in areas with public oversight in the easement placement process will be determined How the environmental outcomes affect the easement decision process will be addressed Theory will be advanced by examining the geographic effect of the easement tool and how social factors may influence its use in a single spatial and quantitative framework Broader impacts will include better understanding of the complete conservation easement process for planners and land owners and the training of undergraduate and graduate students

The "Carolina Dynamics Symposium" is a continued two day weekend conference which will take place in April 2016 at Furman University Greenville SC and in April 2017 at Agnes Scott College Atlanta GA In April 2018 it will be hosted either by the University of North Carolina at Charlotte the University of Charleston or by Wake Forest UniversityThe Carolina Dynamics Symposium is a two day conference that has been taking place for thirteen years at different colleges and universities in the Carolinas and Georgia In addition to the traditional lively interaction among mathematicians from the Southeast there have been hour talks by invited leaders in the field from outside the region The Carolina Dynamics Symposia feature one plenary speaker who will deliver a public lecture on the Friday before the conference begins as well as about three hour-long plenary speakers during the conference weekend All meetings will also have twenty to thirty minute contributed talks and invited talks from Southeastern participants Typically a significant number of talks are given by (graduate) students and young researchers The conferences have led to successful research projects and publications in the past We are continuing a very successful model with participants of diverse levels and backgrounds among those a particularly large number of female participants speakers and organizersFor further information on the Symposium we maintain a webpage: http://wwwdevious/~ppunosevac/cdynsys/pmwikiphpn=MainAnnouncements

The goal of this project is to develop improved models and numerical methods that advance the state of the art for incompressible fluid flow simulation The key ideas are the better enforcement of geometric and physical laws in the computer algorithms building a solid mathematical framework for the models and methods developed and the devising of algorithms that will allow for efficient implementation on supercomputers Although the simulation of fluid flow is a critical subtask in a wide spectrum of engineering applications current tools and techniques are often unreliable and it is not uncommon for state of the art methods to take weeks or months (or possibly never finish with an accurate solution) even with thousands of processors to perform simulations of flows around a car through a nuclear reactor or around part of an airplane The project aims to develop mathematical prediction models and numerical methods that will provide more accurate solutions in a more efficient manner than state-of-the-art methodsThe PIs will construct efficient methods for incompressible flow simulation by constructing models and methods that better adhere to geometric structure and physical conservation laws than modern methods The key components are to i) construct novel methods that are efficient and can correctly account for vorticity dynamics and energy helicity and mass conservation -- this will require development of efficient boundary conditions and significant analysis to build a solid mathematical framework; ii) develop more efficient algebraic solvers for these methods that can be used on thousands of processors; iii) large scale testing on benchmark problems as well as on application problems with collaborators Broader impacts include i) developing efficient methods for simulating high speed incompressible flows which will improve the design process for a wide spectrum of applications in environmental engineering in cardiovascular simulations and in atmosphere and ocean sciences; ii) training graduate and undergraduate students through research involvement; and iii) developing large scale parallel codes to be made publicly available as part of the dealII library

This PFI: AIR Technology Translation project focuses on translating multimodal membranes towards commercialization to fill the market need for products that increase purification speeds during biologics drug discovery and preclinical research and development efforts The multimodal membranes are important because they will help to get biologics to market faster where they are needed to service the large and growing population of patients with long-term chronic conditions such as cancers cardiovascular diseases and autoimmune disorders The project will result in research-scale cation-exchange multimodal membrane chromatography (CEX-MMC) column prototypes This CEX-MMC column has the following unique features: rapid purification of biologics tolerance of feedstock ionic strength high biologics binding capacity and disposability These features increase productivity and decrease purification costs of biologics by reducing processing times and number of steps the costs of consumables and fixed capital expenses when compared to the leading competing chromatography columns in this market space Market entry will result from use of these products in research and early stage development laboratories where purification speed is essential and customers are willing to try new technologiesThis project addresses remaining technology gaps as it translates from research discovery toward commercial application The first generation CEX-MMC developed in the NSF lineage award demonstrated unprecedented protein binding capacity at high ionic strength Dynamic binding capacity results showed that the CEX-MMC column has high productivity; however protein binding kinetics must be improved In this project new membrane coatings will be designed to enhance protein binding kinetics In addition nearly all performance data have been collected using pure-component protein solutions and low titer cell culture supernatant and almost no work has been done to quantify biological activity of the product or removal of aggregates and other impurities In this project antibody media will be prepared using commercial cell lines and used to collect these essential performance data Two biopharmaceutical companies have committed to collaboration for assessing the performance of the prototypes using industry representative process parameters and monoclonal antibody feed streams Evaluation of protein recovery purity and removal of protein aggregates will be measured following the CEX-MMC column purification step These are critical performance measures that need to be determined for the Minimally Viable Product (MVP) prior to commercialization Strategic commercialization and educational plans are designed to validate remaining parts of the business model canvas and create new networks among inventors entrepreneurs potential investors and potential customers Broader impacts also include training graduate and undergraduate students to better understand technology commercialization and entrepreneurship and pursue careers developing new purification technologies for biomanufacturing Graduate and undergraduate students will attend lectures on technology commercialization held at CUBEInC Clemson University's life science incubator A collateral benefit of these lectures is that they will give all project personnel regular opportunities for direct communication with business leaders; entrepreneurs; and potential partners customers and investors in the life sciences Students also will complete a course on technology commercialization designed for engineering students MBA students will advance understanding of the market value space potential customers and competition landscape and seek collaborations for launch with selected industry partners; and evaluate potential distribution channels and estimate the associated costs The team will use this knowledge continually to refine the overall strategy for translation of the research discoveries onto a path towards commercialization

Threats to scientific instruments and data that are accessible via the Internet are ubiquitous The SouthEast SciEntific Cybersecurity for University REsearch (SECURE) project helps protect the National Science Foundation's investments in scientific research while providing scientists with tools to safeguard intellectual property and ensure data integrity The project team provides education training and selected cybersecurity services to NSF-funded researchers across the Southeast The team is multidisciplinary comprised of cybersecurity experts (both research and practitioner) scientists and experts in communication Team members are located in South Carolina Alabama and Mississippi with strong representation from Historically Black Colleges and Universities (HBCU) This program raises investigators' awareness of their essential role in creating a secure and trustworthy cyberspace and offers concrete assistance in risk assessment vulnerability testing and mitigation tailored to NSF-funded scientists workflow and program size Through past collaborations the team is well positioned to leverage both national and regional cybersecurity organizations and programs to effectively reach the target audienceSouthEast SECURE impacts the region by raising cybersecurity awareness; providing concise training assessment tools and one-on-one help; and assisting in preparation of select cybersecurity metrics Student interns are conducting many of these activities by means of practicum-based deployment and support thus developing capabilities in the next generation of cyber professionals An online survey of NSF-funded investigators in the region will be conducted to learn about their primary cybersecurity challenges and concerns Training is then tailored to provide concrete and practical assistance in how to do right-sized risk assessment and mitigation A "toolkit" is provided to test and validate local cybersecurity and measures of cybersecurity are created and field-tested The teams approach facilitates communication between research faculty and university IT/Data Security staff A long-term goal is building communities with common interests in cybersecurity and a commitment to helping others; and building connections with other regions and with national centers and programs

Data provenance is the ability to track data history including things such as where the data resided who handled it and what systems stored forwarded and processed it This research builds on the architecture of the digital currency Bitcoin It develops distributed data ledgers - similar to bookkeeping ledgers - that maintain data history so it can't be manipulated by hackers trying to hide their activities Data consistency guarantees that everyone gets the right answers about where who and what regardless of which ledger is read This software advances the security of computing systems by making data accountable especially for online commerce and big data ("the cloud'') It secures forensic information taken from compromised computers for further analysis It validates whether privacy requirements are being met for medical records The key outcome is a software prototype that implements the complete system and illustrates the ability to store maintain and update provenance information for real data A data provenance framework will be designed prototyped evaluated and then delivered as an Application Programmer Interface software library and distributed service This work will produce a reusable distributed service architecture achieving scalability by using distributed services that maintain ledger information The system leverages Bitcoin cryptocurrency by building on Bitcoin's block-chain architecture to maintain provenance metadata securely It leverages existing tools for provenance data exploration and visualization Digital signatures from both the server/system as well as the user creates dual information about possession while distributed ledgers remove control and maintenance of metadata from the user who creates it The prototype enables research into long-term provenance creation maintenance and utilization for workflows in the area of cybersecurity as well studies of how to integrate and secure provenance into existing file systems and network services Opt-in and passive (involuntary) provenance systems will be enabled using the API library and distributed ledgers prototyped enabling data provenance for systems where needed notably high assurance cloud computing and scientific workflow systems The tool can be used to enable reproducibility of published results from archived data and artifacts

Understanding the molecular behavior of frozen water is essential for predicting the future of our planet Frozen water is present in the atmosphere -- in clouds -- where foreign particles such as mineral dust promote ice nucleation Consequently surface-assisted ice nucleation ie heterogeneous ice nucleation has a significant effect on cloud microphysics This implies that it is important to accurately describe heterogeneous ice nucleation in order to be able to accurately model the weather and climate Though theoretical and empirical descriptions have been developed there is still no complete description of the requirements of the heterogeneous ice nucleation process and no framework to know a priori if a given surface will be a good ice nucleating agentThrough the synergistic experimental and simulation efforts the foundation for molecular level understanding of heterogeneous ice nucleation will be built The focus of this research will be to relate the effects of surface charge and lattice match to heterogeneous nucleation of ice with an emphasis on the free energy of formation and the nucleation rate Straightforward molecular dynamics (MD) simulations will provide detailed insights into water behavior near mica surfaces and will be compared with experimental findings In addition the kinetics and thermodynamics of ice nucleation will be calculated from simulations The research will provide the basis for building predictive models of heterogeneous ice nucleation that can be incorporated into larger scale models relevant to atmospheric chemistry and weather predictionThe simulation tools developed and results of this research will provide the basis to answer several of the top 10 questions related to molecular behavior of frozen water as listed by Bartels-Rausch (Nature 2013) which are essential for predicting the future of our planet Phase transitions assisted by surfaces in aqueous systems are relevant to a wide variety of fields and processes including biological assemblies surfactants nanotoxicology semiconductor industry food industry and others Also the research presents several learning opportunities for graduate and undergraduate students in different forms The collaborative nature of this research and the exchange program between the two scientist groups will expose the students to a multitude of tools used to study challenging problems in atmospheric chemistryThe simulations will be used to develop informative videos to be used as educational tools as well as for recruitment of students into science and engineering User-friendly modules that enable students to perform some simple molecular simulations which can be used as supplements for class lectures to illustrate concepts in thermodynamics kinetics and materials will be developed These will be available to the scientific community free-of-charge The results from the research will be published in peer-reviewed journals and will be presented in various national and international meetings

Faculty in the science technology engineering and mathematics (STEM) disciplines face intensifying pressures in the 21st century including multiple roles as educator researcher and entrepreneur They typically teach at both the undergraduate and graduate level They write proposals and secure funding to support students at multiple levels They mentor undergraduate graduate and post-doctoral scholars They present and publish their research outcomes in highly rigorous outlets They are expected to communicate their research to a broad array of audiences such as the scientific community undergraduate and graduate students K-12 students and educators and the general public Societal needs of their expertise include discovery innovation and workforce development It is critical to provide STEM faculty with the professional development to support their complex roles and to base this development on evidence derived from research Much research has been focused on STEM faculty development in support of teaching and student-centered learning with less attention on the other aspects of the professoriate in the 21st century Therefore the proposed workshop will bring together participants who are scholars practitioners policy-makers industrial partners and thought-leaders to assemble a research agenda on faculty development focused on the STEM disciplines In this project a group of 30 experts will convene at Clemson University for a 1 1/2 day workshop These experts will participate in a combination of plenary sessions and small group activities to identify the outstanding research questions associated with faculty development and craft a research agenda The primary outcome of the workshop will be a set of effective STEM faculty development characteristics that can be implemented based on the outcomes of the workshop and explored in future projects The findings and final report from the workshop will be disseminated through a project website a collective blog and presentations at conferences Widespread dissemination of the report will spur new research on how to best support faculty in their role as educators of future engineers

1602451MishraSouth Carolina has recently experienced a severe drought followed by an extreme flooding that was initiated October 1 2015 The combination of the extensive drought from the previous months followed by the historical extreme rainfall event will likely change the water quality dynamics in rural agricultural and urban watersheds Specifically the deficit in precipitation has likely led to the deposition of pollutants within the soil During the extreme rain event and subsequent flooding these pollutants have been discharged into waterways with the result that stagnant water in urban areas may lead to serious issues of water quality The drought-flood regime may affect water quality differently based on rural agriculture and urban landscape patterns of the state The combination of extreme events is expected only to increase resulting in the need to advance understanding as to how these extreme rain and flooding events affect the dynamics of water quality The objective of this RAPID project is to collect perishable water quality related data that will lead to enhanced understanding particularly regarding how these ever more frequent combination of droughts and floods extremes affect water quality in different types of landscape Given the need for fast acquisition of environmental related data (eg the quality of urban stagnant flood waters are data that are perishable) the investigators will deploy rapid response teams to document quickly these real-time consequences of extreme floods The scope of activities includes: a) collect water quality samples from rural and agriculture dominated watersheds following this recent historical flood event to establish relationship between climate extremes and water quality parameters; b) collect data on stagnant urban flood waters which may contain oil chemicals and sewage that are a public health concern for laboratory analysis; and c) perform sensitivity analysis to identify the water quality parameters that are mostly affected during this rapid transition from drought to flood The combined impact of drought and flood extremes on water quality is currently not well understood This research will bring new knowledge on the effects of drought-flood cycle on water quality at urban rural and agricultural watersheds The perishable data can be used to improve water quality model calibration based on a combination of extreme events scenarios This project is anticipated to advance current knowledge on drought-flood impacts on environmental sustainability Research findings can be applied to urban watersheds in southern and also south-western states (eg Texas and California) of the US because of frequent combination of drought and flood events

1542727FinneranOn March 9 two ships collided in the Port of Houston shipping lane The Carla Maersk which was carrying 216000 barrels of methyl tertiary-butyl ether (MTBE) was ruptured and an estimated 200000 gallons of MTBE leaked into the Port of Houston MTBE is extremely water soluble and visible sheens were absent within a day or two Therefore the "surface response" of placing hydrophobic oil skimming booms did not contain the MTBE and a large volume likely diluted and dispersed within the channel It is unlikely that standard "oil spill" responses will attenuate MTBE and this research will provide the Port of Houston stakeholders with data to assist in the short and long term responseThe broad objective of the proposed work is to characterize how the microbial community responds to MTBE contamination in marine sediment and to identify specific microbial processes that will attenuate MTBE with or without engineering intervention This is the first time a spill can be tracked from its inception and the data will assist in all future efforts related to both MTBE remediation and high volume spill response The specific objectives are to: 1) use metagenomic sequencing and high throughput 16S rRNA gene sequencing to determine both the shifts in microbial populations as well as microbial activity related to the MTBE spill and 2) quantify the native MTBE attenuation rates and identify processes that can increase the rate and extent of biodegradation These objectives will be met by testing the following hypotheses: 1) The microbial community will shift in response to MTBE and be dominated by operable taxonomic units previously identified in MTBE-degrading enrichment cultures and sediment incubations; and 2) Sulfate-reducing microorganisms will dominate all MTBE degrading microbial reactions The research will use high throughput sequencing of microbial DNA extracted from marine sediment in the Port of Houston to characterize the shift amongst microbial populations as they respond to MTBE contamination In addition the PI will use standard anoxic batch incubations to determine the rate and extent of MTBE degradation and the projected pathway of biodegradation by analyzing known intermediates such as tert-butyl alcohol and tert-butyl formate All anoxic incubation techniques have been previously reported and will be standard anoxic glass serum bottles sealed with a butyl rubber stopper and sampled with anoxic-gas flushed syringe and needle setups The proposed activity will be felt at the responder and practitioner levels These data can and will be used to assist all future engineering responses to large MTBE spills In addition the basic scientific data can be used to identify specific microbial populations that respond to and possibly degrade MTBE

The Ceramic Composite and Optical Materials Center (CCOMC) is an NSF Phase II I/UCRC which is managed by Rutgers the State University of New Jersey (Rutgers) and Clemson University (Clemson) The Center is integrated between the two university partners and is directed by an Industrial Advisory Board (IAB) comprised of 21 multinational member companies and national laboratories The mission of the CCOMC is to develop new interdisciplinary technologies to increase the level of ceramic polymer and optical material science technology and engineering and to transfer these technologies to its industrial members to foster the development of competitive reproducible ceramic polymer fiber and composites made of them for advanced high performance systems The continuation proposal aims to broaden the scope of the Center to new areas that are technologically complementary and will lead towards the Centers long terms self-sufficiency The programs within the Center focus on the creation of new materials new synthesis and processing methods process based models measurements and characterization methods for complex integrated systems and devices CCOMC began with program thrusts in ceramic and polymeric materials and processing nanoparticulates and processes opaque armor ceramics optical material synthesis and processing and materials for energy conversion As we move forward into the next five years we will expand the scope of our research to include new research thrust areas in ceramic matrix composites and superhard high temperature material In addition we will explore green/ecofriendly processing as potential thrusts It is critical to long-term self-sufficiency that we not only attract a broader base of members but also be successful in securing Federal funding to strengthens new and existing thrusts to improve the visibility of the Center within both universities and abroad

The significance of the proposed project is that it will bring together computer science education and education researchers who have completed successful projects of various kinds and synthesize the knowledge they have gathered in terms of published guidelines for educational research ie "Common Guidelines for Education Research and Development" as published jointly by the US Department of Education and NSF in 2013 While this document is detailed in general information it lacks guidelines specific to a particular discipline These workshops will focus on providing the computer science education community detailed examples of computer science education projects which incorporate Education Research These examples will serve as guidelines to the computer science education communityThe goals of the project to understand synthesize and propagate the essence of successful education efforts will be achieved through two focused workshops associated with major CS education conferences The first workshop in 2016 will be more formative in nature and help develop ideas projects and panels for discussion at the second workshop The second workshop in 2017 will focus on engagement with potential proposers of computing education research and will promote their adherence to the guidelines and their development of well identified educational research questions and evaluation mechanisms appropriate for the type of proposed research

This workshop brings together educators and researchers in the fields of Engineering Design and Systems Engineering to assess the state of the art in these fields identify promising directions for future research exploit the synergies between the two fields and strengthen the design and innovation capabilities of practitioners Additionally current NSF grantees from both ESD and SYS programs (Engineering and Systems Design; Systems Science) will be able to present posters explaining their work and get feedback from their colleagues and the program director Participants will identify and discuss past contributions that have had a strong impact on education and practice and discussed their domains of applicability their limitations and what needs to be done to strengthen their future potential and impact The main objective of the workshop is to enable the engineering design and systems engineering communities to exchange ideas and find synergies The workshop will bring together about 150 researchers and divide them in small groups of ten to discuss three specific topics First workshop participants will focus on method validation and research methodology Many design and systems engineering methods approaches and tools have been suggested in the last forty years There is a need to take stock critique agree on the potentials and limitations of these methods and define evidence-based approaches to further improve them A second workshop topic is to determine future research directions and to establish a framework in which these future contributions can be organized The focus will be on directions that can most affect the ability of engineering and systems designers to innovate and to deal with the increased complexity of products and systems Third the education of engineers and of practitioners will be discussed to identify best practices the right mix between experiential education and lectures and the critical topics that will provide the breadth and depth required to move the fields forward at the various educational levels

Rising rates of chronic conditions such as cancer and cardiovascular diseases are driving the demand for biologic drugs used to treat them Currently there are over 130 biologics approved for use in the US with a market exceeding $140 B Over 900 new biologics targeting more than 100 diseases are under development New product commercialization will require significant expansions in production capacity and improvements in manufacturing flexibility to meet future market demands In addition the emergence of biosimilars biobetters and increasing competition will apply economic pressure on biomanufacturers to innovate new drug manufacturing technologies to lower production costs Innovations are especially needed in downstream drug purification which often limits the production capacity and contributes 30-40% of the overall manufacturing cost This I-Corps team is developing a platform (PuriTM membranes) to dramatically enhance production capacity and flexibility in the downstream purification of biologic drugs The disposable nature of the PuriTM platform is expected to reduce biomanufacturing production costs significantlyThis project is expected to accelerate market entry of PuriTM membrane innovations by developing the entrepreneurial knowledge and skills of the I-Corps team that are needed to translate the innovation from the academic laboratory to the industry sector PuriTM adsorptive membrane modules are single-use membrane products that purify biologic drugs They are characterized by high drug binding capacity high selectivity and high tolerance to feedstock conditions Laboratory research has demonstrated that the firstgeneration PuriTM membranes specifically address all of the known customer pain points Through customer interviews and use of the business model canvas the team will test the proposition that these single-use adsorptive membrane innovations will derive commercial value from their abilities to increase the production capacity and flexibility of biomanufacturing facilities and lower the manufacturing cost of biologics Identification of early acceptance customers also is expected as an outcome of the project The team will develop alpha prototypes and work closely with potential customers on external validation of these prototypes Completion of external validation will provide additional opportunities for the team to understand customer needs and test assumptions about the product utility and design It also will provide vital data to attract external investors and new customers A validated business plan and minimum viable products areexpected at the end of the I-Corps program

The number of older persons in the United States is substantially increasing as is the cost of health care Accompanying these trends is a growing scarcity of caretakers care deliverers and care facilities to attend to our growing elder population Technology supporting health for older adults tends to be limited to computerized monitoring systems and potentially someday in the future as assistive 'humanoid' robots that look and function something like us Our homes and their many furnishings meanwhile remain conventional low-tech and maladaptive to life changes To promote independent living this research team from architectural design robotics and human factors explores how our homes can be outfitted with furnishings of advanced functionality This project home+ is a collection of robotic home furnishings that fits easily into any conventional home to increase the quality of life of individuals with impaired mobility and cognitive functioning by enabling routine domestic activities This research project will:  establish the needs and wants of older people wishing to age in place identifying those aspects of the home+ concept that best promise to support independent living;  design robotic furnishings accordingly; (3) test these furnishing to determine how well they interact with each other and with the people that use them; (4) define the choreography by which these furnishings and their users interact; and (5) evaluate how well home+ supports typical users performing ten routine home tasks that define a capacity for independent living The team will gain insights not only from the targeted populations and healthcare professions who may benefit most by home+ but also from a wider audience This outreach aspect of the home+ project will culminate in a workshop that seeks marketplace and practice support for advancing the prototype The majority of seniors want to age in place in their homes To realize this goal this project will:  conduct a needs assessment of older adults;  iteratively co-design and usability test robotic furnishings that recognize communicate with and partly remember each other in interaction with human users (interoperability); (3) define the pattern language of interactions for this cyber-human system; and (4) evaluate the efficacy of home+ by comparing performance on 10 routine home tasks defining a capacity for independent living for individuals with and without home+ Drawing on research and formalism in distributed robotics the team will focus efforts on implementing and evaluating three software environments for home+:  a centralized architecture with all sensory information processing command and control at a single source;  a distributed architecture with localized sensing processing and control and minimal interactions between elements; and (3) a combination of the first two with a dedicated interface layer between the high-level strategies of  and the reactive behaviors of  Intellectually this approach can be viewed as establishing a bridge between traditional robotics and smart robotically enhanced physical built environments

High aspect ratio and high quality microchannels in transparent materials are critical in many important areas such as micro-optics microelectronics micromechanics and biomedicine However it is difficult to fabricate them using traditional machining techniques due to the brittle nature and low thermal conductivity often found in transparent materials Femtosecond pulsed lasers offer the potential to overcome these difficulties However the aspect ratio and quality of microchannels produced by femtosecond pulsed lasers are limited This award supports fundamental research to enable significant improvement in the quality and aspect ratio of microchannels produced by femtosecond pulsed lasersThe research objectives are to establish the relationships between  ablation mechanisms (spallation phase explosion fragmentation etc) and machining conditions (laser intensity pulse duration etc);  ablation mechanisms and ejected particle size/velocity distributions; and (3) the size/velocity of an ejected particle and its capability of escaping a long channel To achieve the first two objectives a physics-based atomistic model consisting of a molecular dynamics method a Monte Carlo method and a particle-in-cell method will be developed with laser parameters and material properties as the inputs By predicting the distributions of temperature pressure and electric field within the materials dominating ablation mechanisms will be revealed under different machining conditions This model will also predict the sizes and velocities of the ejected particles by simulating the atom evolution during the laser-matter interaction To verify the simulation outputs the sizes/velocities of the ejected particles under the same conditions will be experimentally measured by the time-resolved pump-probe imaging technique To achieve the third objective outputs of the atomistic model such as the temperature pressure and the sizes/velocities of the ejected particles after the initial laser-matter interaction will be used as inputs into a subsequently developed smooth particle hydrodynamics model to simulate the ejected particle evolution within the channel in a large time scale For particles with given sizes and initial velocities the model will predict their escape or redeposition onto the channel side walls based on the temperature pressure and ambient environment inside the channel Ejected particle moving dynamics such as their transient locations and velocities will also be observed in-situ using the time-resolved pump-probe imaging technique and compared with model simulation results

This Faculty Early Career Development (CAREER) Program grant supports fundamental research on the design of urban buildings that can be readily remodeled upgraded expanded or otherwise adapted Buildings that cannot adapt are at risk of becoming obsolete and recent surveys of building demolitions in select metropolitan areas have revealed that obsolescence not structural failure is the leading reason for demolition In response this research will study domestic and international building projects to identify the physical aspects of buildings that make them likely to be demolished or adapted Findings from the research will be used to create tools that architects and engineers can apply to design adaptable urban buildings Such buildings will promote economic social and environmental sustainability of cities as they address unprecedented and accelerating trends in urbanization climate change and technological advancement University students and industry practitioners will participate in all phases of the research and will be instructed on the theory and practice of adaptable building design There is need to transform current prediction-based design practices which are incomplete with regard to changing demands and obsolescence To that end a Learning Buildings Framework (LBF) will be created by integrating graph theory risk analysis concepts the Delphi Method and adaptability theories from manufacturing engineering The LBF will be the first quantitative and rigorously tested method for evaluating design-based building adaptability Data for validation will be compiled through partnerships with domestic and international engineering architecture and construction companies and will provide an orders-of-magnitude increase in the quality and quantity of empirical data on building demolition and adaptation By providing a means of quantifying adaptability the research will give traction to the "design for adaptability" philosophy that has been widely discussed yet narrowly implemented Relationships established in the course of this research will support development of an international research and education program on adaptable urban infrastructure

Excessive energy consumption is a major constraint when designing and deploying the next generation of supercomputers Minimizing energy consumption of high performance computing requires novel energy-conscious technologies at multiple layers from architecture system support and applications One obstacle that hinders the exploration of these new technologies is the lack of tools and systems that can provide accurate fine-grained and real-time power and energy measurement for technology evaluation and verification This project bridges the gap by building Marcher a heterogeneous high performance computing infrastructure equipped with cutting-edge power-efficient accelerators including Intel Many Integrated Cores and Nvidia Graphics Processing Units power-aware memory systems hybrid storage with hard disk drives and solid state disks and high performance interconnects The Marcher system supports the development of two complementary component-level power measurement tools for major computer components: (i) pluggable Power Data Acquisition Card (PODAC) for direct and decomposed power measurement and (ii) Software Power Meter (SoftMeter) that indirectly estimates the power consumption of systems where direct measurement is not feasible or too costly Upon completion of this project both PODAC and SoftMeter will be made available to a broader community and researchers to establish their own power-aware systems Marcher will be open to external research groups and provide users with comprehensive and detailed performance and power profiles to aid the research in energy efficient software design and system development

This PFI: AIR Technology Translation project focuses on translating III-V Nitride piezoresistive microcantilever based neutron detector technology to fill the critical technology gap in the neutron detection area arising out of severe worldwide shortage of He-3 The translated technology has the following unique features: (i) vacuum enclosure of the microcantilever sensors which will result in highly sensitive detection of nuclear radiation as well as protection of the sensor from environment and unwanted radiation enhancing sensor reliability; (ii) possibility of using arrays of sensors realized through microfabrication techniques which can offer imaging capabilities and directionality information; (iii) the usage of bimodal detection technique and two functionalization layers to perform highly efficient and unique detection of neutrons Thus it provides exemplary performance cost savings and efficiency when compared to the leading competing neutron detection technology based on Boron-10 in this market space The project accomplishes this goal by using a relatively inexpensive material with unique material properties and adopting a design strategy involving the design features mentioned above resulting in a novel neutron detector prototype The partnership engages Savannah River National Laboratory to provide guidance in the He-detection market space and other aspects including prototype testing and technology commercialization as they pertain to the potential to translate the technology along a path that may result in a competitive commercial reality The potential economic impact is expected to be in several tens of millions of dollars in the next eight years which will contribute to the US competitiveness in this highly critical neutron detection market space The societal impact long term will be in the creation of high-tech workforce and a safer society with vastly mitigated nuclear related threats

The goal of this project is to study ultra violet (UV) processing as a viable pathway towards a sustainable method of manufacturing layered fiber reinforced materials derived from biological sources for structural applications A key challenge in the processing of these biobased composite materials is that traditional thermal curing approaches cannot be employed since the constituent natural fibers which are primarily made of cellulose and hemicellulose start to degrade with prolonged exposure to high temperatures UV curing is a fast low temperature photopolymerization process that uses significantly less energy than thermal curing If successful the study will enable a cost-effective and greener process for making high-strength thick laminates that are highly critical for lightweighting automotive and aerospace structures Lightweighting is tied to achieving improvements in fuel-efficiency and reducing pollution The PIs will engage graduate and undergraduate students in this interdisciplinary research project and train them in understanding the integral role of process modeling experimentation optimization and control in advanced sustainable manufacturing The PIs will also leverage collaborations and interactions with industrial partners to broadly influence industrial practices for processing biobased compositesThe specific technical objectives of the project are to first extract physically motivated and experimentally verified process models for UV processing of biobased composites and then apply them in new layering scale-up optimization and process control schemes for building thick structural parts with these materials The basic phenomena to be characterized by the modeling and experimental efforts include: 1) the nature of the attenuation of UV intensity as it passes through the biobased resin and fiber systems and 2) the nature of the coupled evolution of the spatially distributed cure and temperature state The project will also investigate the potential of a stepped-concurrent curing and layering scheme that will exploit knowledge of the cure kinetics thermal evolution and UV attenuation in these materials The project will apply a new hybrid modeling perspective that treats the addition of layers as discrete events on the otherwise continuous physical processes involved in curing This perspective will help generalize the scale-up optimization of the scheme with the goal of building ever-thicker parts of highest cure quality with minimal time/energy needs The project will also address process robustness considerations via uncertainty handling in the scale-up optimization as well as with online feedback compensation

